{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import math\n",
    "from skimage import io\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "\n",
    "def load_data2(txt_name):\n",
    "    path = open('/home/dl/zyfang/face_example/'+txt_name, 'r')\n",
    "    lines = path.readlines()\n",
    "    X_train = np.zeros([len(lines), 112, 96, 3])\n",
    "    for i in range(len(lines)):\n",
    "        t = lines[i].replace('/media/sdb/ECCV16-SIAT/','/home/dl/zyfang/')\n",
    "        t = t[0: t.index('.jpg')+4]\n",
    "        img = io.imread(t)\n",
    "        if (len(img.shape) == 3):\n",
    "            X_train[i] = img\n",
    "    return X_train\n",
    "def load_data(txt_name):\n",
    "    path = open('/home/dl/zyfang/face_example/'+txt_name, 'r')\n",
    "    lines = path.readlines()\n",
    "    X_train = np.zeros([len(lines), 112, 96, 3])\n",
    "    for i in range(len(lines)):\n",
    "        img = io.imread(lines[i].replace('/home/zyfang/caffe-face', '/home/dl/zyfang').replace(' 0\\n', ''))\n",
    "        if (len(img.shape) == 3):\n",
    "            X_train[i] = img\n",
    "    return X_train\n",
    "def downsample(img, size):\n",
    "    im = np.empty([img.shape[0]/size, img.shape[1]/size, 3])    \n",
    "    for i in range(im.shape[2]):\n",
    "        for m in range(im.shape[1]):\n",
    "            for n in range(im.shape[0]):\n",
    "                im[n, m, i] = img[size*n, size*m ,i]\n",
    "    return im.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Data\n",
    "X_train, y_train, X_test, y_test = Data.loadData('data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import imshow\n",
    "from skimage.transform import pyramid_reduce\n",
    "i=30\n",
    "#imshow((y_train[i,:,:,:]-127.5)/127.5)\n",
    "img = y_test[i,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc82fefa590>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOYAAAD8CAYAAABjJ9hGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztvWuwbdlZHTa+tdbe+5xzn33VUndLLam7JQGWIEKUIoEh\nDkEoEbKNVBVCAFdQXKrSHxMLYmKE8wO7inJBlcuYBFukbdnIKQpBBLYoQsCKJMdFpVBoSYDRA9To\nAS1arX7fxzn7sdaa+THH+Naec+99zz33dvddrZ5f1b3rrPdcc+01x/xe47MQAooUKTIuqW52A4oU\nKbIp5cMsUmSEUj7MIkVGKOXDLFJkhFI+zCJFRijlwyxSZIRSPswiRUYoT8uHaWZvMrM/NrP7zexd\nT8c9ihT5ahZ7qgMMzKwG8CcA3gjgAQC/B+D7QwifekpvVKTIV7E0T8M1Xwfg/hDC5wDAzN4H4C0A\ndn6Yk6YOs8nQFONSQ0Y+eNiWvyQ6tqriZKBp4nXNLNlvPFfH5efr+F2iFs1ms2SLmqrrzudzVJUl\n+ySL1SppS37v5Wp5TW0PyPqHx+fL9cZPa/WLNqXXqKqaF9NzpW0LfZ88t9+Dx3Vtm6z7eTz+thfe\nmd1X+4Ez586l7V3bdzWxXUdkm0PWHXn/Q8/mLyzA1A87nrvX724y5TV0cf2+DF/44hfwyCOPXP2H\nRXk6PswXAfjztfUHALw+P8jM3gHgHQAwbWp8/d23+w+tZkepD1q+ZP/oNj6q4QfYLuOPXR/Mrbfe\nmqyvVl1yj/39U8m18x+g7qH1Dulx99xzD9saG9txube3BwD4kz/5E/9bx2j5+Qe/ktxDzzmZTGLH\nPfBAsq79asupU7HtXddhXTQY6Zl1vqTrOrzkXOyXepLeO7BLD06f4r3ic7bdkteOBywX87i/j/ee\ncHvgYHLxsceS9WkzSZ79nX//H8Z1fTUWB4KlGb79u97MbXERuK/T70IfRfbB1aFfPw0W9IFxA9/Z\nvInLmtdtwOtzoOyPjuKS6w1WaOp4reXRRfZT7K+GfXs4j+tnbntJPHfO32p9io2Z4LV/+bW4Vnk6\nPsxrkhDCvQDuBYBT+7MQgg0DFXu2D+kPWT9AR4I+/hgm9RoqVjla1MmyqvhSNQjUdXKPDXTWiKgf\nSZ9+mCu+PI0RdaUDY1srCwh9y7/jvmZCNGrjuTrZ9IHVbDuvYfxaKg7Dlem5jYdXSZtqtoWPitB2\nyf7Q9xv9FNTuDF70EQgRtF6p39QmPkOv66nfaMboswFtIkRmYwPX+3ZtkOn6pG1W6ed6neoXH1H9\nV2Uzrl0zjBCCf9RLvTNrk5Z0XYqyfg3HjpO1+ekw/nwJwIvX1u/ktiJFilyjPB2I+XsAXmFmdyN+\nkN8H4AeudoIhjsBVNk74GMPRVLqA5XqLD3CVI2MQigh9d4yywY/XtdJpoaauG3oK0Wxap8jrCNtx\nqmNAt1wk+8BjJ5YiXMd7cFaIhmikpR6z5nVWi0XSJumFg1oTz6sbtU076kH3bjhl17SP6FRl5+h5\npS8vOYXtuVx1mvLG67Sa5ei6vfolrq+WcYor5AVn26vlcqOvB12al9qlSrKDNsBph065SwzpuzSY\nX8PVkpC2v5JO7epVqq92od00MlxFnvIPM4TQmtkPAfhtADWAfxlC+ORTfZ8iRb6a5WnRMUMIvwng\nN6/5eABdB3RuytJ1uLTUAONGAR0nPbKqfITyuX/LkZzo0bYa+anrTFPDUq5jCs0GvYM6FQ9r2zhy\nhj4dKWVMOTWbueFEItSpuoh4FaTnEq1X8dx+fggAWLY0ThCVhGbnZxd4QRmq4vZajZZe6M889OPh\n4pBtiOdIVzbqrdOW1kUC2koI2WXom81QrOa9ptHwlOvy2n/mIBpFWiLqopNxZY5clpwZ8FVi4pbw\n7eJvMEfQzAI92FzTdy6dVrOKOgCo4jtc0cij9z4Y7vwXF2/lv1X+Hvv8LleXEvlTpMgI5aZZZdel\n7wMuH26OlLmVrN6hG0wmHEHr2q2mMq3LiiZdR8igEbyZRJ3BkVJ635r/CQBqjoxu6eRxTz7xBLfr\nfCIqzzt3Zh9mB3rSpN1v+4H/JmmLrM7SlT73p1+IfxAJl0Thuo4K2cc+/ol4vPtJ5f+M15lTt12s\nUqusmSEQlaUjeb9MG7aBqDHN9lMnPSt3CtF8Ij90iEjbhdSyLMu5nvGf/dw/5bPF4yb7sY+avX18\n55u+K+7ai+91urcfl3wnepdpbw6W8xxtct2z7WhJh9xzRHNeQO/DDdVrVtoH/+Kh2IY+9m091Wwt\nPveFlSztnHHQndLU1bG+8XUpiFmkyAhlFIgZAtB2YVO/E6q5ryvVNU3mOdcxG1glXZE6pZYtl7SW\n1pzxL7kuESKqZ6qwfeyST1JO6J7IIP8leN3bLpx1H6lGbD1n00VHdm3T5Bzt7xdX4pLoK/04NPF4\nDtaOqOqOwFnCQnqhfG8UqyrMl3GGIh1JUUhTIp70Yuviup4BMlrLAmxC+Srpl5pttMx3G3if06dP\nAxiQWK9+MZ+jZjCCzNT9IrZlzuefndrH1cSRM7ekS/Vu5ZuVtVszMvm6+fLXEZMXW7Av1T8TnVPL\n/M/fU51GhKHvgBNomQUxixQZoYwCMc2Aum62hMURISuNSoSIoIiQuNrb+rXc2xf3UcGQzrcrskeS\nx1H6diGhwsGIIApF02kVgWVB/W5iwNHyiA1N7z0l/DRc1jy5J1JMqa/qGRQeVylMjpZVoVNFPU66\nkWYFU0EH9zdN4xE67lptLF3WdbIMmbVRCNrKktyl/bzydxiS/StZX2lp7bLZRNsHgNZQWdh1zal8\nrzxWz5nrmpJ+x7v0iJ8hUDg7QNuFnCu/2B514eWK78JDvvjb1LpPj2hhb0/mxyyIWaTICGUUiBmC\noQ+G3uNQ0/15HKsvOfrOZtQZtiDn4E9KY2Rz/9qApNlIT/HIGI8EikjRruLIP6Me3BCdlmDAeehh\n0msV0SNEoB/TiJSV+8KIPv0y6Q8CKGpOFfYUE9soakkWafoSOVpDAeprmRFVlhWj58uXRjxSXwtl\nBAx5kP/gW0byLB33S6N3y6eW1Cvb5WoIXeoUl6p7cHlMZM9xuOSRROrXDce4UI+zgbUflnTMxUoW\ncurQHoyfL3nPerOdV23jtR9apEiRZ0pGgZiSXalX8lMq5ShkES3zebQwtm3rmRTDsfFcRcVUGVLO\nZqn1cMrzDq9cAgBcuCXmBs6vXI7HK7aUI+TXvfxlcV2o7pkksR2vffVr3FKMLvUn7k/6pC1qQ8uZ\nw10vibkAiqEdIpzi8nWvj2lEga9xvoz33mdUzf/17z4IANjbj1bM5XKwQP/uH/5BfN4pLbwTpXNF\nvfWxR1O/r2KNdfzjjz7MtmazmQwVPCsne7fd7EnwoXmephMT/P0f/dG4TRkssjrzmH/wD38y3hvZ\nPZWwIn1vA0lTvbDyE9MoJldatyivk1n0e8/2lNEUr6l+kt8SjAWWbu3XvkYpiFmkyAhlNIgZOvjw\nmut3ubhVjfN7qT9VGOJtFQUja+KgP2idUSSrI96T12KaQ5BeqAwNol6j0dbTF1NdTOvKAKktuG8P\nmT6rtExXgz0jJraxc/YAPYKGcLZB+alE+Rmv17DNU89SkRmTz9BMMZOfFor9ZLv1PJ2ShGlFVVYI\nZydKENbIPoBLmvGzyZ7AXNJpOlORr7av6o0EeEVzeXhuqr4NIhtFJes1b5kdtolG6RahvPJgYxM5\n06J9QFb6PsvKcUevUFttapf+27gWGc2HCWCY8q0xEgCb+rTEvQBrBhvzl8Jt3hlpELo6dqYQNLEj\n6EP0lyNzPj+WNn0hoUtD/qpe01V++F2Htczv9AGYFd9b1jY1WYnCupd+QE4xEpLn14fc8uNRW1bz\nGKiwWrJtkxVqD4Tgx83lnlwS/IEpYHxGA5ISn4fwwTS9zvxR02f2/Xw/V44YRO9WJLp6moknAMj9\nY3IDZWGRVd6t6fgziI9s2YmZWOY+cRsQaujddJ7exv5jwrRCDj3bX0ESYS3BooTkFSny7JZRIKZZ\ndNT3GdILtYRubrJHur3x0D0bRk1N4yoFoafeaF1byJHz5iBEJJzUNDRNlNzM6RWnujKG1EIxpwPh\n9et6Le2I6OvTNx6bj48+5RR66QJKGCZqkd/Inf2rNtl/7hSTerm+mgwB/I2MVDKG0WUj49cTDM7v\np7xGp2kijWSzaFASEqp7ZajqfaqH5DidX+9Pk/srDC5U9ZrxJoVhd81kU9kNEi5NfS09rt/h4N/l\nfnGSLtQw8PfAwPpa75dqh3iVlkdxdjJp9K7jc8WIvGufyhbELFJkhDIOxIRh1kwGkzpS9JKep/hg\n7Xd6D7oDpk3lScdOX1mnDnHpDUKIy5cej9cm6syoG+iee3Sn7BMZ9xop9XH/LefOxutrmFUjOWof\nHBw40g96LN1AlcLdUt1jQJGUqGpw4sftz3ve89hBadrYhPQX99z90vhM1BNdL0SF17zu1bEfiE7t\nSkaueO1PffIzSRsUSlcRAf6f3/md+JhEd6XJLXvpYCJSI3JmKVQPPfJw8kyaLS1XHRq6JFZ07wxx\nF6nLwVPwtHuXbikRfO/yXORB77ou4Drw819wO9u94C3oJuF7v3iRLHohutvQCfsq152vRQpiFiky\nQhkHYhqDp50BMKXa8ORnhpiZWz7ldmBYVFW58uj0HU4NIrQSraTC3qiXCU1kJOR+hdrp/InSlzj4\nCY3kkghdil51PRn0LaGpDbrL+nMMNI1ESOqY0qFFEiVn/8C3S8twlw75Z8k7qzau8/PWIvoy6Zjx\nHAVmHF58nOvT5NoV16Vry+kvP7ratvR3p3tKqedMZqrAD9JbelbZam2mwP5ww3o6s/Bgdq67WyVT\nQgci55Cct0s2jKdrG9SXnlBB3VNuuEcffix5HuuHVLKTVD0oiFmkyAhlFIgJcBTzkSkNyTMPCkgW\ng89S62sjm2WO/5yyUKPXbBZ1ypXSeEQt4sd1yfk9LZ8KXu9alTFQDhqtuGsk1Z1So+SLrhTQnZFM\ne2ZZGsQwtJzIu1HOQL7FOHqvmATd1FH3XpDUywm3zNzH6XHaRMS9Pc0Aopyijt162+Wv44zA0T/z\nOethMxSTDUB+TLfABpFa9YMunKX/DWl/ab9s+Lm1dJPwtSFVjpS+buZ3EylZ1ZOehH7MmtQqmtVN\nJ/vJ8xqqk7gxC2IWKTJGGQ1i9n0/1AvJ92V/Sf8bCIwp1jtSagTP5/WKohHxkmgIV6yxMckSXoWg\nVeYPDf120962gj7+t+u9Sj2bJG10hJBemy1zXclLIsiP26SEVznJ1/pxs0Z6fLykCKoG1JEurlVS\nakhP5bpH9CjyRedlUTgh09Ub+X89TFEhke1gGECKnCetTJfOv+BE4Tci6mM9v2ZGdfZ78+fijKRt\n25PkSRfELFJkjDIKxLTQYy8sBtXAs0vldFQEDKMosuDkrlZ0RY/KGFxNHeAVL3wx1zWSp8hwz4Uz\nSVuUCKtKWnfccUeyvlylxFbnzkVdQiOpyL0crVYX/e9Vr2pd8diDU9EH2mchT7qWooo8sZqi4/Pt\nkjxwfBtt4uu+8ZsAbCY6S/6Tb/hLW68h9P7e//avJ9u7TO/9hV/4BQBrET9ZKt8vfTBWZZxO4/ua\nLy6zPQGPPjxJ2qa0PqX//fOf++m434myY7/ukZ3s1d/4SgDAbCZqFhFrx9/Ay/6z72Wj1Fq9U0UW\nVcl+CxWqIPLn09xHSlKZjOdMQXw0Pt8ixMgp2UEsZAWTjpGCmEWKjFBGgZgALY29UoYUAZRGAgWP\nFU3F5/VxJV4vq0UpP6VGV7fk7UAXT+jleUsmvuaIuUuuRR/apTttUKgcs/965CTkw1c73/VWFdvt\n0hjcVZfW9HQfZacsnrh+QFJnq3rv67yNk2aWbG9qZQZJn5c9QL5RxQ4TtSa7Qn74TBvduQW33DKc\nm3CzMhSemrLuHSh+zCJFntUyGsREsEF33DGYD7G0qSiyvw69JxPXIR3Ra/cBphkKQsQ8PjWnb9Q9\nnDyquvYx7TgEfKployz7FsrOXeXgd53r74TrR4fRD6mEafXTUVZyUMhoTdpvZ/aijrYgjeViGbMy\nTp/Z95nTqdPxmDmzaC5fvsxzaBGeynfK7BqiVjPxcK94T9osFLV1whqyqXiIkuJeu2TZud+b6K2o\nr25XIcjtct2IaWYvNrOPmNmnzOyTZvZObr9gZh80s89yecv13qNIkeeq3AhitgD+Tgjh42Z2BsDH\nzOyDAP57AB8KIfyUmb0LwLsA/NhVr2QG1EPZ2h653selU9lrB0u4KYokBKeK7GmVbRkF4yXuvEQC\nrYlZHmbvJRXicYusOGyXWURlrd0l29DRs0xy6sds+y6L6a6S5Pn+q23fhZieBdJv12slymxRjqP6\n63AR+1v9ov5V1FG3EqUm7QZcnzI++NT+AVZzWlFPRQvobBKt0yp1ePbsWTZKBGKRHmZBYm1Zs+fc\nviJ9zHyR2hey/JGrItpAN5LaPwYyBOq9jUi3FRklfbd7ZooKhRAeDCF8nH9fAvBpAC8C8BYA7+Vh\n7wXw1uu9R5Eiz1V5SnRMM7sLwGsAfBTAbSGEB7nrywBuu4YrxOh7JSBwq2ec+0CT6UpcfemLX8zz\nevdXNly+7O574r6Mk0cRPa966YvifupI81VqEcwRUVbZp0LH1OiaE1rXmR6761759hMhqAfipmiR\n619DecL0GgcHUf8TcbZQ6na+C6GatntWBo9/9es+C2AgTAYz/h9/8nH86r95PwDg0YcfYVtV9DZe\n63/7+X+eXGtC/+WZ01Hf/YZXvzy2gesqJVhnsdWSnBXqatCpjB/vjoynav90tC6L7Gz4LbdDQeFr\nkBu2yprZaQC/CuCHQwgX1/eF+Fa3PqaZvcPM7jOz+9qc1qNIkee43BBimtkE8aP8xRDCr3HzQ2Z2\nRwjhQTO7A8BXtp0bQrgXwL0AcGZ/L1jtHAADUiofT7pX9okrZnZxdMSHCahDmiXe0icmX2jtw2Pq\np8yL5QgpFHWi9QWvd5yOuY6Ou6yxOeLlFtENJoNs//Xqmlc7d8NnmlljJftiT9Cg6nG8sf9Uyt3J\nualLzuXnVDY/T5tSjzyzv4cldUy99ynRNjBi6vTpiMYrXkNFZGUPmIr5kBE9c2bXdCx7mHPvrFs3\n4v/Ze1nvog39NO0X/S6aiWKr1S8n8x3fiFXWALwHwKdDCP94bdevA3gb/34bgA9c7z2KFHmuyo0g\n5rcC+O8A/Ecz+31u+3sAfgrAr5jZ2wF8EcD3HnehON8dxojecoTJdct0lFYpvAYBDbM+pFOKJa8R\nF5AK7mT8qLleJ/FsAqFVplOdRE7qx7zW43eVFswRdtsxfmxmXcxrKG0I/Zi5b1nWWY+hzWYkYkw4\nQ5a8Jy5F7adraf1uBj33FEveBeaAXrxEBjrGzMpCrhSOpZjsamXz6DdA+4KnymhW5cSxFP1GMuRc\ng0wVQg7KR5XtgqUzxC8sXmGPQAsn82Ne94cZQvgdALuw+Q3Xe90iRYqMJvLH0KNaG31z/lhF6Cvd\nPq36olGrRhh4XZ1hXCXoqOt4vibvvMFZmsbYCgF8PTNUzbyc3W7ZFeu6a/246zwlEUSZVfZakwVz\nK61lBZFq5SeyP9sMUZ2xQKXSCY9ikghNhXYedcGes5XJPq2rbhFlJI+yazy2Wpk9bCvLGFbGcg91\nGqXjrdL0YANmtL3y/F49V6dPRxQQJlTOzLG6xwntmyVWtkiREcooELNtWzz86KNoGE8plBIn7GnG\nTE7oB+rFn8p5/dlT1EXaFjVZ6lSD4/YX3MZ1DaMcXduUQTv3Lbo1McuV1Iiv7RtROn2qu63HpUq0\nriwKSX7PPBJoF0LusrBezXq7ynRBy87J0SkXxcoeJ7tmFN/6l18HYOiD2SnyE/Utqv9VbSSqdntJ\nWzw3llFdqjY0k8+U1ZT2yCIvc/6K8bhgJFA7JwsB/aTTWYw0WhDdGsbzAhUWC7aTHEgDx61+T7E/\n73jxndycsucBvccVX4sUxCxSZIQyCsQMiBYwL8WWMRQMbHnaogpcca2pB7QyZZVoJ3PyFCobsrLn\ndZ36IfsMIHZlaOyKd72aX3AXCl+rrnhcW/Ljrnb9Tb6kq8eL3lj25mZE0YyZIRXbcXglFrJtTp3C\nhH26fyb6Kw/nAx8uAEzEuyQ9WVxK1PeMfs2+n3OdSNlFlG95LxUIricRWdtVPL4jr3EgE2Ld1M6H\nq9/HwAKf1pOppVyuISXP2N4xO6QgZpEiI5RRICZgcdRTTGSXWc0ykZ9JsUKy4tWhRyPdjzqARjZl\n2JvyKndAw65y8/l+b/kx0Tfbrvl052Pm993WNqFN3g87n2OHLroheQ3QHXLpyUcBAKfORs6lmry2\ntXXO/yNu2qNlXB6cPgcAWDBrRMx+TUNrrOdCquhuXDIQCK0Y+vaoRxMZMcm4chmTu/Bc1B6V15nh\nobLmOwewbBNpla+BRrDHSeYdBTGLFBmhjAMxDYDVQ/Shu9h2cLeGdDlE/hgmKiUuJgJds09RVrmd\neQUmsb3tsmgOoaPbY223odRxbAEnlQ3f6zXGym5r0wZbhG1H0l3XHnzM6fmSXc84nfE+tVgH4vql\ny0/gwoXzAIAn59ES6hkoejeqs8LGT7yKuHzXtHZ3stpyRiXd8yjqmJ0Uxjpajue06J95frTGNh4g\nVKHPjA85corjp0LqW80KmV+zjOPDhCFU9doPly6JzGKgqY0CEPRx3XpLfJE1AioVb1UiLj/IpYq8\ntlmI2CwLtta7ykiU3S2S/SA3PuyMqmT9XjldieS4D3TXdHoXfeVx5+ft23bt3Mhx3DXzAcvvs+P8\nFd0JDz8cP5IZ08gODvbwo//Tj8Rr8t1M9+J09/Jh/ODe8573xHt1TKjmNBMM6wtt/BCPFrEw0tIu\nsW1x++XPfjJu56urJvHeXRWNQK86fysfSm6asBGy7r2XGYFUZEl0l8MJFU4yQS1T2SJFRigjQUwG\nsmdhYk4pko3OOf2+QrMmGMzvXaCpnKjbizzJo6zSqawHG2fgUmchZ97eXTSZW10T6RT2uICB4yS/\nznVJlSHeLmTk8tjghny7jEA7pu1TBgHUS6I/p7JPHj6J88+LM6BLhzTiiHZSVJA+deU15F7r0qls\n3zJlr2LyO1H68DCi9HIlojDS0Bh/M41cbvoBbvazO0G8g9QPDCJQhwaun6DMO1AQs0iRUcpoEDOG\nrl2dkHdTpD8yWLmyjXJ77giWjqgitzSJH5e8eqPEyMDx7pKruTW2teWpcLdszABkWMmxb0fbhqCP\n9PxrlccvRXdJwxQuoRTQe2LzlUM6/GnC22MJeyVENwxar5o0/E3UkUpSlrtkQl20Z8C8R8gxSfvK\ngm2gMRFeCLj34PQN3MtsPIOoOJVS02zrUbukIGaRIiOUkSBmRMs8BG9ngFimEMmcXlc1Kp/LM7wv\nS9/Sld0xXJG2IqMl3LhlToC8i2oybIbb7dJHb1SeihIJG2idXXOXdXbX8ZbZB3a1UcHgNe0DV65E\ny2lVNaiJnufOxZC8+TLtP3/fSK3cHnYpkmUWiOoZaNBS1zxSiF4lkq7YllVqYHfKzbrqFZGHXa9u\ns59SupKTSkHMIkVGKKNAzBA6LFcXnRakUfw5R6wXvvQlAICK1JJTjogzDiu3HlyI+7ulh2VNmbLT\nXonUFbMmHcF6pv7UFsO89piM23Ua4VjaTYVrOBzL8rdP3agRu1dgWpAspkT15eHlDSusQr2sYgk/\nlenj8waGiB2ci22rObIvRJ2porPsj7yMgco45GUJ1lHyspdej6JJiOg3pBrV2QxCiOD2gCGCIy7d\nuq0ZCJKlZNGyBOFS1myWWpg0eMmt8bmrSUrfIt/0O39QZfT4e5iwxH0X6S73p9RNaWVtppotxePP\nn4rvru1V+Chuv3CGCQ1ttNpOZySW7o+8QNGEvk2nwskerHOdU3Oz9RDQomMWKfKslpEgZsBquRzK\nhVNEzhzc2hYl12PW/YTu2xK5llBjoqD21N+okd+tbhr4M0oMlXrzmjJOIJ2m9YhyyXVQq/1cPYHa\nrWsI6roMdTr3jWa6qZKxOcMIg2k0Oa7u2GbdfV2v7Pp0Xxbm6G5IBWXn23tZcSXbLc+7dEwlqLve\nrcSEqnJ/dn4N9a37b8PVQxL7zM4Q6AddddJZdX1Ljh/Cv3ghM4SnwDp/EimIWaTICGUUiFlXhjN7\n+050pMI/1sYRTv4nq2h2a0UhmMar1n3n8bQtL9VyVK05CiroWKOnKCI81jFotAaPUyJsSNddoRMF\nh8r96bLDaG5IR3YboD7eUwgh01+21LWqkOqObo3Mi6RmpQS9kOuapbSpRNXIUzPEVGpdTVS27Dif\nxfizaD+D+91EiuQ4LQ+fuLS+24NrqkmDSavY4i55HkP6HGqTEg/6dOLgswG9M9+vRGg/TgHoeVFa\n7x1PLD/WEL7LoXBCwC2IWaTICGUUiBn6gHa+QKeskTYtANQzsqfmescE2ZWoIZStISpBYIjRVLk9\n06grfS0e1mU6k+gmBr1FQ7kiOZi9ogwY6Y35CMlniKP5dsScqYhQdm/pPisf4RnhpETeTk3iyO+U\nksq64bN1XbofGNZr+fiQnOOM/hmC5s9nG/5PpG3v9K5SZBX6T2cs7e78MEPfCCGHmGn2n0iVpZpL\nJ2ejhZxDESL+vCtau0U7Q7/lUBpBxynONbO4rvXfsdFZflzSNGxC6NWlIGaRIiOUUSBmU9d4wfnz\n7vtTUVlRTn7ty18BANhnCe+JkIYsuqeYyxf6BkYoFFtE7SXYssI8pMlftqlVsO1k+ZNOGi/k+poP\nynH9kBSIORrqOm3bbkT6eH7mZD+5dtulBYuaeRzZm7bxa8XjUyuuI2JIc0GvmhnTpq/edcss9jNH\nSu3fVVJiSfvAnCXf5Zv1BGwe/8hFUXemObaL5RJHLH6rGOhcr5tM5FtmZpCJYI3PJ0u7+3OZU9vT\npzjl78WT5mkhpo8SpowQ86VHhG2k0WTrOULKloEeJ0HNgphFioxQRoGYCD26oyP0HPGl99V7jGNV\nMVnqBh6YoxOVAAAgAElEQVQL6eRJ8uetZafI0qniQbKASseU71DKVCfEZCEakStJt6zzjHSOssz7\nrNxqx/txNF+1/QbLgRBsTsSf8Jq5jrnsXXHjfvnjYpsmeQ7ojpw/RzX32/XOxCDJLZk5gkqkxefR\nTPI9CsVFKD1nvKpE70pE0Hpl6/mwS56TW8Tla27dzxu3Tzr5nFN7gr8zRW9p9tPM+KykpCHbQOe5\nlLLOrlNTZnovtou5ni/4XnsnJ7DMFsQsUmSEMgrErK3C2f3ZBk/PnkreeSk9joyZ/1JW2r5rhyiZ\nLo3ekPV0w8elHD1nPqBe4vpFSujbi/JQKoT8mB6PSv1ON6q7DSWpyqx/IbeuqjwBdewgHcnzDLNY\nWEdWtoEwJ1+lR/xUQ4m4Jis7vqFL6o+wHSE22BiqdH1YipxKuY6xTVcuH/JRZfWmbt62rqe2fZde\nw+kC5GvmO8OgC64tHEFbRQD5xEJW/BRJg79b7V+zzF9z5E9a8Gro2GdYxzSz2sw+YWa/wfW7zeyj\nZna/mf2ymZ28kGSRIs9xeSoQ850APg2Aofj4aQA/E0J4n5n9PIC3A3j3Va8QemCxQOflv6lDIuoC\n8mduUgOGdNWGCA2j5bKqmbXQZFZZ6oAi6h0cT2yC0CyL9PEYWg6/ykZxAmDpORq9e0NQbGudosPK\nVUhdk02Rv5bbFY/rPlefFaTrgoTKY0tp/fVoFHeMwrrt+mgWduuy5snjJfIjpFvHtdZVd6WpiGI0\nimJlNxFz5RE+zkSoa1SykHNGwTJ7yHzKwREyRdKW72HVJaf5u+qGuC2ep9nUwK6xC/Ncp5QVNuRz\ns2eQ88fM7gTwVwH8C64bgO8A8H4e8l4Ab72RexQp8lyUG0XMfwLg7wI4w/XnAXgiBK+l/QCAFx13\nkXPnzuG7/+qbXVfUaDHhyLjPbPdpk+pivSKA6Cvb25+iIcHLk0/GnLoLtz4PAPDExZiX2dAXuncq\nllx75OHIPZr74+bzaG390/s/BwDuW9O9ZV185LEnkvMV6TJlCbi/+PKDXhZ+gxx6L6KGuGyU87c8\nivd6zTe9Oq7PyZdKiNyfxpnE6//T1wIAWpajE1pPmUmz4nmTaVpSbzlf4M6XxNeyoYd6mUJZiNNy\ng6oKe/lyLGNQuz4cn+Xilbj90mFkCbhEXVL6sHy0v/XbH077k+9lPp/jBbffDgA4Yum7qpkmx/7Q\nD/1QvGalglEx7nYyi8d/6S8+BWBgSWjbKzw+3vuld9/DNrGYUCvLMv2Y+gWqkFDbe+CXRzhtRPak\nWTi2gZTPEGKa2V8D8JUQwseu8/x3mNl9ZnbfFX4ERYoUiXIjiPmtAL7bzN4MYA9Rx/xZAOfNrCFq\n3gngS9tODiHcC+BeAHjJ828NDQbf2oCYbKSsss5gLp1Dmf9DvuJqEdFT6NSuUl+f1g9DRBNFl+Ts\n6F2bnpcjqiyFihkd+HyQrHddl/y9fq29qSJ/lFUjThtGqFDnEaqpTWKTF1uclM2qVk5p9szU3TUD\naZrG0XVDV9RzuK8YyXGKKfYCv0hnCp63qXheZbbwfPW32jLkxYLPXm9ELiXW0TXxUoKV2PLT/qtr\nxTWzP4WAXjIv1UkD8vsM2SWyzue8w0+XXDdihhB+PIRwZwjhLgDfB+DDIYS/AeAjAL6Hh70NwAdu\nuJVFijzH5OnwY/4YgPeZ2U8C+ASA9xx7Rgjo2+UaU53yFJV3Sd2Smqv8dBvFY/uggc0jSzSynzpF\nNbhKY1r7PUWZxN2Obq1GX/oK5TPN2AQcOTxWNkWUSd044oU6zchYEfG6FblnqCtrhrBiwVbpcaFa\ny54BMKNl08iX0yiGdqmCq/G6Leu2rOdS1k3aD4OkFtHcDOn9lrEsCEmaRpkbV9hGesvYBy37r2Ob\nlBHiqbbLlfMqdaStU8xrq8iwLkf5dNYi9F51mjmw7Yp/dt+sslL0qNvjYa/N+3hjrHi5PCUfZgjh\n3wP49/z7cwBe91Rct0iR56qMIvLHLI72PrIp+8Kz4hkRpKHM+UOJQLKIVUOERk294/LlOHIrrlYR\nKvIpevYDRaOt1zqheKZGn+pmOt+zSrK42MVisaHr6dgL56PFWIjaTqh/EQm9FocspyHVjTrXrWmd\nrIW00Zh2/pbINrdUBSr5aEPlsaySwdUpXVJ6l5BTSJqySsguoP5UHO/88Ijny8LJ/vd3yhv2ii0d\n/MBiyff6JoyUEnvipJIOyXel/EpT/qlQXc/Ee2ZFdfMZWi4bJQpPJBmChpNpjSVWtkiREcooELOq\nKhwc7A06I1L9p5GVzvJ5vFBqzYekOFoi2UMPPQQAWDBDxf1PisPN9BUhal4fc9LI30c04/Evu/su\nbqeFmEgr1NubNpgwm0GIqXt86S8e5rHxHo6+fL7HvhL3V56xEXVH+XMfezTyqIpxfFILKeJ9XvXK\nv8R16cODBfXgzCx5bnjJculfzGN1hoI1CyWAz3/+83GzqV/S5/8Pv/P/Jus5G8G3fdtfiX0iRj/1\nQb/CS+66O+5Tbiz1ViHgqVOR/7Wmzq7IHc0IpuT8rcm83vZpTm7vWmVqGXZep5zxwbZYYzcUz9yS\nq2nd9emeBTGLFBmhjAIxgTjaeZyrtmVRFTkTQJ3pBmbmJwvpFKHi/DcZYiqmNq/hYUQ5+QY32czj\ndVrP0Gf+pdaVU7lc7tRHz5AtXpFB7XSV3OtxIqJCOD1H0qRj0lIsRvZaM4i4vr+/z3VaNz2l0LAU\nevssRdemr7PWduWhDrmcwFp1bGXKsJ9q5jYeHR0l10fG96v+kR9Y6zVq17mFcDUjdFZCfsXMUum0\njm1w6zxnDm5p5yPIauuVzbSe+s+vKseZaDcQ8vqwryBmkSIjlFEgZkBA17eeVeDZ9bkPLcuqV0ZH\nvR7Fwn179J8pWkjxqH5P3mJfmfeyxmpUnmi0pp7rWSZEQupOU8at5rGm0ueaqnbd2NkQKMtFRJU+\nY5TbI3PDainko86UVTaeKtJHATBcrlb0Y/LZFffrtL1d5wz1A6sBEdItuFWyHjIly6OLlKVDgJjM\nYj87NxD7x1kmeP6QS0sWCvHRhuB5uc5MD8XEpn5K96lmzA3eNqT5veqnnNldP6zgS+yU3KqsO9cb\nSLpF1zyBmXcUH6ZBKVtx3UPzNpJ3U3eBh3ux4xftaggiz0q5K/1rcD7H7Q3JunI3h4fg0Uaibyrw\n7U6UEtTrR6IfcDrt7vsWfZ+FrfH5FJLnU3X+IPPAcjntwY8gZCF5zqyppO+MtlJTW02Zm6bxa3dI\nfQr6kWvQa5XGpN8XP44pg9ZXbfqx6Ael558pAT1z/jfZILUe8jj8nQ4SllGLDseJlDo7XvQvnPp6\nodpMhmCKa09kvnZxR9SJzipT2SJFRiijQMzKKhzU+27mDxnb8DAyZqRUNKdrqhZCcHS59GRM85rS\nvbG4GKeN2t8Q8W4/iKb3MI0j25zoYjTff+5zX4h35nC7oGuiY5Pe+J3/JQDgzJkY8idEuMi0M6DC\nxSf4N++tYz/8+x9O+kHGIbkDXvjCFwIADkjP2c7SIf9hultETuYpVOyvP7v/wbiu4O1+MMi87Oto\nxCGiefADjz17Kua9y9m/ZAhdRUKK9/3yv43nU2UQfYcSpG976cvjMwmBuV9upAcfis+02o99c6WO\nz7I3OYPqz2Kq2PnqHK8ZjWCXT8d3+vLbXwMAeKSJqXtNewsA4NwqpvAp0Xyvjc/bmVSDeM/Zfkwr\n07uaUF0RSddA0UJ1pAbads6+JApnmDZMpoWQQnFZ7voT0JMUxCxSZJQyCsQEkJREHxy829cHSQPJ\n+74fzPgbSyX88kwaM+ZMtpZivugU3ten6wz/Wim0T1QTNPI8dimO/KtFRB4lMz955TIOThEdmPh7\n5egwaZs/Tb/diCE0y8MHJXkg+iYhVrVx3JAAkKZM+ewkO1d9LHeKUF9IOG/TIkK5kz5/hltmqS4e\n3KCwhj3XqPPlZNsD+Rh1UblqiF5dZmxT2KBl/b9+/We4Cl9BzCJFxiijQEyhZY6Y+Si1SfUfl+vp\nPmbpaOjWUeaMVUp4FfJNIpoNCEE9lzpmRUtmmKhQjSyCTJSmjiWCqNkey7TvRYvr4XLlxW0mtGQq\nKH1w/OdJ2CnC1c6mNUn2X7lyhdsVCM41WVw9ED9F5riPiBmyfrIs4dtSZFPKnahDZA5QMdjJnoIa\nWO6B607ArfC5Og19lB5cVdUmAroVPkM80Xlu/A7kehHrVh5wkCaSb6R55VZas2OLCT3VUhCzSJER\nyigQU2Je4kAUHKm/SknIQ9FUjaC0vnUBZkx8RqpTeqEeUR9yBFwIGjggLrJ0pCuu16U6p5Ker1Bv\ntAylHqEl9uyFC1iQXGvlAfNED0+ZSovDStPxcoOrFCmEMpNJZvnT1eUE31ZMiNsVnJAXHqpVkCcj\nsPYwSW5XIrpC7SZs9PQgBhg8eYlobmmCtKy+SgZXbp+sw1aFQbfmLKdlgMFQVGmgSAGGEgdVVihp\nUFGJoJmV38mqM/9nLrHfCmIWKfKcl1EgppmhqqoNHbPKUrC8yGlGJDUUuOn87wlD6hTIPZ3SZ8WU\nIKHPw/R3KkRNCcTyUz706GMAhiRkWR9Fd/Fz7/55tk1pUrwvQ9P+xx/+YeyzSKtHLHF5ukstoSKq\nEmmw/JkyWGq/BvYHH4x+SkVKDf0Xz/cwxD7X3Q2nT9MHSNRR0rVHJfHc2sMk2Vbq1F/zNV8Tj6fe\nN2cgvQLCH/qD/wgAOJzH2cx8merTb3njNwIA2v1IPXmljv08sT28YPoSAMCZLrZx0UWK0Ctn47Gy\nCNf0czaIbZpU8V4qitu0Kq8nS3Ncn2QhQG6Vzco5DOlgQEHMIkWKjAMxJYNOJGtcap2squ2j1rpf\nqqpSi5usf6Z0pia9pifjEo1XWdn1hVKrllwXyjVxOZ/T+siIkAXb8tgjEQHOn7sF80MWcVWcqEiS\nZYlUUraK5MiqqLhe6VxZcLpG/gExM5pMkZrlRVTNMGFEjyzF0uPy+FSndsz0/Sl1zIrWa1uJlCzu\nVxyv7q3yF6ERuvG6qpQnypcQPN5Ylt1WRYaE6qQSafjzlX8Ssnp7cLtmCrLKyiKcWandtiF6lPT8\nZ9yJiYKYRYqMUkaFmJuFaqIMfi3fkhwvH2XX9agqWVHlr0yRwM/pZeGjbugUkdRrOcoKWWrXz2gZ\n5eh8SL1lSt1rxhStBcu4L+crdCtRf8R7DJkZEVW8IK+sqXVuJSQBFhHSE6uJQiqp5zqRCh2pX5QB\no6JDdb1BPj0EvchvuT36SggoP6b6TwWQZvuM6yXa7TEZfCOCiFZt0aE0KhAFW7MlRKktRWs9X6to\nLul/rbJpiKwiyK4UraVUtVSf9nAlZRtu8W8WP2aRIkXGgZghkFJ/h9V1WHKvq6IpzUUIYaP4S+6b\nkoFOS6cG8UJFGl2piy6JNrLNeUnAeKN9Lq88Hq27S1r2zp6N2Rnzi5dxy9lzSVsOSanp/kuRSodU\nt2x7FuSlJTinv8xVbk+kZlyvkrsdgVS1vq49Asr1MyUV575jKCaYz03EO306IqFiZRfStbNyh/I5\nt8u0JIUSrHuV0qsVatR53GxeTDfHEcvyMOFFhLk9K9vXN6k/eMjb1HVlhU2XyheOz5O36emRgphF\nioxQRoGYZoamadbm9mnUzhCpoTOkI8QNd9xxB4CIKEJPRY9cuijC53im9gt9zuxd4I7MWktkvOvF\ndwJYK8CasQvI35eXVPDY0sUCj335KwAGmhON2K9//esBrPvLqL9mDA11RmuiQrVf/PwXsC6yLHsU\nT0YDuk4LqmvJetpQ752zdN/58zHHcc4iTdJrpYq+6hu+HsDgF26dNSHun5AeRZQknvtIPfnRR0kr\nepk+yiouT+1fwAtuiX5M+VpXIjOb8fmIhKugmYF3QGyLdO/Mz71apjOOnB5FJRSqSRr9FLAedUXL\nb04Eh+1ixx6xXQpiFikyQhkFYkrc8pVZYXdaZYHsuC3nZPqKOapwNKX/bigJQJQSEXErIijF56YW\nPSGNdSnaaTSuux61yutJZ3FfqHRjPkhIR+pBR5Rflwd2aUSUcGzIO8yQMlPWzAYKyJy208+V/kZa\nTs/MyPT+nMvHEzPaLGvFM0JoYT5FJJ2k961syDJyXVvxyRM9h1i1aFGWbi1/JdLt7s89BrSeacvr\n1aQgZpEiI5TRIOa63nO1Y+IfGpZT/SXmY6bbhnJxKtATku0zMdBl4qTATl+Zj6b0wykTRnw7ym9U\n8Z3QDRSHjvEsebBWcHddnNBZPlY9v5Ye+9ol2/3q3O7X8fsPMw3vQvhJcX0XrGRFhVTSoK4Gi/j6\n0ssT5ogsSs1FZHFY2ZzPypKETetZNT36reduSsqqN2QpqemcBfR5Fk4aaTYmuSHENLPzZvZ+M/uM\nmX3azL7FzC6Y2QfN7LNc3vJUNbZIkeeK3Chi/iyA3wohfI+ZTQEcAPh7AD4UQvgpM3sXgHchFrM9\nRioMY3uUXVwug7JJlHI/ZufZ/kNsrPS2TCek7jR/QiwAqWz4UB3VMl9aUMn3fsdyNaT5aySXL7SJ\n0UFVn16zynIUmywn0n2pVbrdaXOy/sr5eYHNeFwlVrilUlEwQhs5TblD/kirFW2T8vIqL9X9f9IT\n2dqD0/E9LA84Y2EZhFkz8wgpRfz0bqXWzzWPqZbkfs4Md7Kixdc+Q7MNK+zTLdeNmGZ2DsBfAStG\nhxCWIYQnALwFwHt52HsBvPVGG1mkyHNNbgQx7wbwMIB/ZWavBvAxAO8EcFsI4UEe82UAt530wruQ\n0gbTKhdxXFEUSttOE8a8KCmHjfZrhD84d+GqbcjjNPMCpLfcEmfqQqA681Xeddddg4U2Y4P/0pXI\ncjAU4E39bpuISRQmAj/04Je5PYrK9fl8Qn68DBgMPVb0V4pZoKL+Nfgj1abUUqwY2pfcdVey3TmE\nlA+rwkDqjzaNTZ5ZzDVtD2KO5ZOInLBVdwr7FTNXYhPRt6kuPiBdhiuOcKKmT9ePs7pusOxd9ein\nV25Ex2wAfBOAd4cQXgPgCuK01SXEHtz6fGb2DjO7z8zuu8jKUEWKFIlyI4j5AIAHQggf5fr7ET/M\nh8zsjhDCg2Z2B4CvbDs5hHAvgHsB4GW33xaA9REt97tlfs0qsxCuxcrmiLlrXdc8XKQ6poeVZry0\njdtGMwbuQAui65QqnkNrMFYbJUs7KC8ztWhKxKSu+h67EHPQMbU91bkGnTOtTwKs8bz28r/KL6lD\nM70+Y7kb2BSq5Ho5Q0Tt7yrNfNk7HXXLjtk4bYj6dt9OnMPHlulsJa9psskCm+NM7gfehZzH64/P\nmuySEMKXAfy5mX0tN70BwKcA/DqAt3Hb2wB84IZaWKTIc1Bu1Cr7PwD4RVpkPwfgbyJ+7L9iZm8H\n8EUA33vcRRS9P6TBpRw/m5E/6fZ1n2WnjIyNqltaKquB1siZh7SkjXIrLlFrw19HBKm0LkZxxsr6\nddbW3LJJ9gPy5Fh2b8XUBrExKCPGQ4lTi7HPMHJe3j7XF+Hrg68v91/mfZ4iRe6nhOevSse2ZL8f\nR1EUjvyYYUKWAmPWSdc4H2ze7rra/nPNdaXdNoqTod66VfaZyiqR3NCHGUL4fQCv3bLrDTdy3SJF\nnusymsifk0g+8q2vHzda5jU1O0s1lSGDg3Gacui5RTBF2J76Yu+5e6qHIWbzztnMzXWj1IKb05lK\nL6vq1AdbZ4jp7IEeG5sip7olZxYPIQzxuH3Kc3Ot0OA8QuqHLGZWM5e25axmpZhb+jHJdNA3KW9P\n15tXextiZcUrm/q5T6qJHRcrK3m2W2WLFCnyNMkoELMPwNFRGCybHPkbZh7MiAiNLIWOSvRFkv17\nMq03GAtUW1IjuqJH9veJShzZc/9mxQghMRFYLZ4e6qbk+Dl7LrITiPGgk+7J4fbxVUDHbg6tECse\ne/D8eO4kqwQtlvIHvvBFAMDU0v1aX/XzoQOxad0ddCQeJp0TAU/On0z6Rc8vK+0hfaxeAbpWPma8\nx5XLlwEMqL1s0+u89EUvjv20w48ZjjjTsPjuTlcx93LZrLAIMTfz0qnYhtZosUU8xo6iD/SWQH5Y\nL2JDnqXmlQCAeXhRPD6wLijjcm0afdfBo5zYf7QXdGJTwJL37dFb8L+jyCKurBiu9+Q00m+V79pC\ndSL6g4KYRYqMUEaBmCHEkVuI6QwFlayucevgj9LIn+sc26ywqQ4UsupWs0zv8Htkg9uuuEpHAOX+\nKWNf1wvBR88+0/nknxyiirQ91Yc1KufHC828rbllOdezw6A7bfIpyZKbrhNAh6pfOzQvc0vqdt/s\nlhPStq0t9by1t1cxs5L0d+IETvn2bOkzCP3OhJRQrm3cPDAAuUd4uIbv5TvKMlueKhnFh2kWGTvk\nnFd/1BmNo4wg6pyANAggMQqJqpDUhbW/lCo7NvtxH9dWLuW8X4lcyttUrV1VicUZdSYvMs0ML6GT\ngYTblWysxq1EbxFXG1JnKmD+Wn8bNTZJyqosEECDQKizQYL728wV49fZcc/NEovpNHt7wH16tVr9\noNECq+w4Bs7rnfqHS/VEpNZB58nQJ6taytSm6Wkk5bK1v9fu6VNVbs2msC6ZkfE4KVPZIkVGKKNA\nTImmme70zku/+yIkSyf4tTBMQ0I2GmYjmO+v8ulehqidlPu42u5KCJYrhCOmk36YrU3+UlRSPdqJ\nH5sGgDdZELuG5Sqbbg8UlLxOVqx327QyDwj3KSuXnQxVCt7ICKzyQPmcrlJTW7gxLEfMdKkk7tZq\nR00PqICWorhcpg/jsx9tj9HvFRHV6WA0jwkMJ/R+kXUspcHUdStUQ4hiMr0dxNfSiUAa7HeC+IaC\nmEWKjFBGgZh96LFczodULZmmNS1n0rOrFp7KFRHh8iQGoldryLBRLt22j0Ez0iyKANlTp3I7iusQ\n6fqFc+fZIo22CmL3Mzcc2x5KSHeHG5DalKj5gKX85B7p6jZZ7+m018guNPIAdZJZd3kqlxkWR3QF\neEpamxx7xIwfp4KUO4n9o/KGrhP2OXKmQQ0Vsn71kMDUMGMw1E5GzX5S33sAhXRF38F1ISXzxUy6\npOgphbh0n/hboo0iRJfQQEGyZstwQ9T2T2Z4xbkueTLdUlIQs0iREcooEBNAHEoHuz+AtUBxp/cY\ngorXt3cLhoGtWb6arIjNoIal8CV9rcrM9kLQQZdS01K3gmgw5C4ZgtdlYTa/ihMNy+q8jCO6yqtL\nxRFiTrxobGqa97QwpHrPoOeyFdIXl5uULblbKU8IcOd7Tk+p44WQVYaQfbbMEdT7R2jnreLmaqBl\n4Z5GKWn+XNQlqxR1YSzSpKXrmKI9UTmMQ+6Xrp6X5VOjhhIMNYMZgqMzsnOQnDO0ydL1a5SCmEWK\njFBGgZgGg9X1QM5M6Mj9mFpXgHgV0tSiEAIg6kZZNmlhqzIdc6DdqJKlbfildML2trcL6mpeTpzo\nJfSubCMo2tfdwslRdaVICllK6bfs0nWF9NXUvXOfpJepk1VXeq8c6FXlPlCFmImGUu2v/Nran88g\n2H9K2vaH69OlkMKttEju4+IzFfOUtCqk/TaY5YmYzhimGUHcXlPHDHbES4sYTMcdZuenpd9FvI1e\n24MbOES+tmF2zQNSTmCB3SYFMYsUGaGMAjEDArp+NQSae8lyjpwc6JRkq6TkIQSN40vfD2FUfep3\ny/2brlvlqo+WHsEhPQ7J8Vp3ChJZ8IQEjpwDAmzQJ5LYeCj2k+qQk0yntKwfVJ5PcOX36dM+8FQ1\ntd2qgUNEuuZGoR0uHejkG031PwcG+QpFb5LpmhsUmlsdffHpdGwtPVaH1rmuKFTWTEMIKQ4pWmlN\npRN1vOhkpA/yuu4FqLP9axKyTyZzheZ+TAf5EyJoQcwiRUYoo0DMOKz00JCl8gSKXg+0KrYcKXPq\njIO9fR7eDTomSxuoiGlV61HT6KLFEUfVlZJxU7+dyuxV6ioP6o5/XLoYC9YOxXaIUmvI6RbPzEJ5\nwDZOmuhLdR2SaPbEEzH9SUWIekbjqFT8Y489BmCI/Ak5InuG0ub2y5cPk+fNk7blQ6xns6Q/VqvY\nXxdufT7bGvU6Tw9j6bwvff5zAIDTp2OKlpBYvtXz587ENinKxkvGV2hFRi1LblYi8Yt/8PF4TZVX\nIC1Jz/SuPsy5pK7pv5vYhj/83Y/EZ5dOT//ldBZT/PYPbo3r03Ns0x7aNrbz3IXbY5P4zjr20xEL\n877kZffEay/YBidea9ZM+8dLQcwiRUYoI0FMxVhmJlD3AWVxiR4zK+rEAWk8AajKdKRa+muaxbDL\n/7YRueJ+zT45P9c5PZLF05+GfUM6kdalv0rfo+VPSJchbE7foTZ57LCXEsyjcIQ4vKyFod3uTkx9\npdJXlZUj32qv1JY2jb5p3Keoden9igumvjxlpJXCf7PqRn3Y1O9dH5auKKss/ZWBSAkiKKClEDOj\ne2kznVIRP1JVO62zzWGJjrplWO3xVCVvq7aEnxzb6IlSmrHVa7/n46UgZpEiI5SRIGYArHedaCj5\nriE+TU7V8KrMEae7rConLlY0zUYR2EzfamT5NB/iuD7heROu59dJ16UX9541geF+8r9mCOhk0vIz\nVqlfcyg7J2sr8wqpl1mT+vuG2BJFIal/1GuDL7KT3uqJ5GnUlVt8PYAlRy9eSykyvj8tAbhqF1gX\nfx8sIpRH2QRrhnmTU3/oHpr+8JpEyop+yUCktKAIIFlvdUWWm5dvW8/Mfp/SDjGp4/X8vWDlqHr6\nQNk2tEloNuPJ18r95B09e6crOmaRIs92GQViBkSrZvDhOS469yHmOmcqQ7RO8GOHkuO08GU0EwOb\ngDILuLcVzQTzA9u0nJwspxrRxGAgq6wXvF2LWpKukiPmKqTo5ERgIaUOcV0yO1/Hu/XVM1yoB5vi\neLV/aOP+NC1lkBMz50Vi3YecIeOQAsS2UX0TQdqukneLJfVC+QWd8mU66G2ePaJ9jH11/y8twhWR\nktwjbscAACAASURBVIhZSfdE2jbz2dCCz8hHILI6oVYnBVj5nXsIjAJqV7SgkyBs0XF7pyghorQX\ny03f3bVKQcwiRUYoo0BMII5uXtrbC9rsOji1by6Xmtf3nplQr4iIRK65dL8BXgAAnXRI0TDSLzeZ\nUMckkizkx+tSv5+Oc6ItbyL1xEkzoEbG+yIUki7jPlTqYYeHUdeZMK5VpMktda3Ll2IEiyOpc9U0\nfm8AsCaNBQ0h4Fd/9d/Eazpipih9110vjc+lCCn6XMWK8JrXvCYeHzSjQNIft9wSfYD1VIWCU7Q/\nfY46ZlAGB9exh8oytG3Iq1Qxj1L+SSEl8ysr1u3rTHmZvEUWyBp6MTtwgweSRbRb8HptFdvRokFH\nRDwS7WdF/6xFvy2a6APF4h52RNxfaSZiVbHKFinybJeRIGZI5uCOAK5bansat5rz+KyvK8pD0R3O\nnJblx3V5ZgZ10pbo1q2Ur0g9J6PpVzm6LtOD5cfq+xZVk+prub7RWYpWgWjc54TErhdTRxWrngMx\ns1Ea6XXMvvH+hB+/Rx1zYDAgiTRnDLXyTINyRuUjTfM2VdJ9aGPcfurUC5O2eAt5nuuYyuDwIJ8K\nDe9tntHCe1XyX0q3lj4n66tiY1lYys3Rtr7AxNJ+HZgziP70k7adIokatGxn0D76SHvqlJVPmWSF\n1gxAroaTBcsWxCxSZIQyDsQMcaTdZCLbJamO6fl7FobCO4pVdUOv9Fb5OakDuh+Tvr8dpcrz4qkb\nS7ZIA2dF/57V9UauY14+T9E2uX8zX3oOpNrsfLq8d1Zs1vc7obTiePukdOH6OYrT9YI+ipKRv1Gl\n4Z1TST8honi7TK6nGYVEzzCZEZGZQSRds0Kz0efB7xUPVZk+U8nFiggK6Y6aJcmqK+RVfqraIu5h\nIqfzD8nWoeimBjW3TfdiyY0F+2mlezX8oTWCfqix8dr9M+jHNLMfMbNPmtkfmdkvmdmemd1tZh81\ns/vN7JdZO7NIkSInkOtGTDN7EYC/DeCVIYQjM/sVAN8H4M0AfiaE8D4z+3kAbwfw7pNdPY/13AhI\nTWTwNQ6jZJWhkpY7qH82W5DzpSrPMIutdf+n65hZfOraNbOw0OFerkNvf+48VhZIkVEjvUfv0BJd\nu+5Eq2+QXtjtLEDknEeKnc1mBrkPVYVqa88OSc9TNk6O/qikH2sWsd4hGV4oOkm6ofPDCjmVl5r5\nVJEL7Q5E9YHHmOLX11UUQdX5u3O9s1P+KvXheulnxQ1ymmo2Z8+oVbYBsG9xPnMA4EEA3wHg/dz/\nXgBvvcF7FCnynJPrRswQwpfM7B8B+DMARwD+HYCPAXgiBE3O8QCAFx1/MUM9n25wwVauPPE4E+uZ\n9ELmwl2JJeHma0NklUX47KpNsk/roEZy1eSQPy4sGCVCf5xH49DSurx8KTZRmR9IrZzNtHZUcVY/\njqr7yzTqZs6IFuUoXjgdcxZV3HU+4XM3UTv4xGf+KLaFJfKka4uZfjEnr+wqtUhPqgkO6Pt19gOV\noCMa/fXvenPyPE4jQVT5uld+Hdsu36l8yhE55ofk+l3IkkpE5rMcPvg4AODKUfTVKu+zheEFd0aL\n7kLgsxef7+IiXnO6F/ulq/Z5gKKQaJ1lxI5Y8nL+oQ63Yl2CM0AMObQA0HtObe3RSPphN7Popzy1\nH5ePPU5WhDq25eKjnwcAzKZRJ53M9jDUTDlerhsxzewWAG8BcDeAFwI4BeBNJzj/HWZ2n5ndd3k+\nP/6EIkWeQ3IjVtnvBPD5EMLDAGBmvwbgWwGcN7OGqHkngC9tOzmEcC+AewHgrltvDXVdb+g5kmEt\n072Ga8VlUoYujbIJeYk6HSWrJPUy51vlICzmcRMiOt9Q1kZH+TT7pKoqZ+yTjlRLT5M/LmduUEyr\nrId6bkuPE2oPBIBppscQcZQqtx06jx7qlWWikn70Oy57zQwUNxoXK9/eJMe7bq24YM4S+jpti55p\nPmeUDiGonvI8M0cnZWYow2c6OeAxelxlBKWo7LzDzgsry7J+N5k90q+XxQPLUh/gjmllHUmXxlIx\n1FxnafvQyzfNmOvD1VoGz/FyIzrmnwH4ZjM7sNjrbwDwKQAfAfA9POZtAD5wA/coUuQ5KTeiY37U\nzN4P4OOIU+9PICLg/wngfWb2k9z2nmMvZilK7ixZnu1vM7/fuiI5MOqlmQX5tRVP6tcQZ+su/6Vn\nj8TDxWHjarCjHNfbsIaEGRu3wigbMbGnfre+EfqkuaKhSdFomFKI8U5RTQO37XqbOusxPdhP2q+0\nkMlebNQyKHeRLBE8ecmZw1K6tDcKyXbph0tLGR/kZ24m+3x2vkPWaVm1HUyct+IJaqXzxWM6onbH\nDuwdOYWM8ol6lVJuV9YNdVOKp1L67yyNcgoAevEP18zKkeWYEUHN9AxPjdc+2I+o3NAe0Afb4Da+\nmtxQgEEI4ScA/ES2+XMAXncj1y1S5Lkuo4j8CSFg1XcDFymlGohhuL55HoCB0TysI2Jqld1lnXWe\nHOVfOkmQfIOpbtmKHZ3H7x0cpNdTDUs1tln3EaaVwI5WqtPI6lweacLn9/LpZAPw2pPx2oushoey\ncpyNT+XZ6/Q8GPDYRTLwKRKKVmcx9l1aRGv16RnRZxp/KrN9ZtkoG0WWS95rpTjdmdjvFGMaVxVZ\ndbSQlVf+wKhzLnpDqPfYDUTGIJ2TMwhlzQgBla/p1ldV5s75ZPUuz/L8bCYma6xPRAbEHMrNK1NH\n/t6IkA2nBIeXFaMdl5OJzgtrMc3Hy2g+zOVyuVa2IG7PU6uGZF2dGBfzdauukwTL+ZwFKWTH6VLu\nLqHzWVPc6ZzulDZO+Vp+DMbjH308mv3dxJ4HnGcB+rw5AOD0beeSe3n4G4O4WxlWuL6iG6RhGtcP\n/OAPsF8UmqfI+bjIgyKcgiUAr3rZK5J2zlexD4/Yl7fdGWkaj/iBzjmIOB0jp56DqyHes5nwHpye\n11380C1zSXzmwejqkdFtpYpK0xnueAXPncUffauPgn3+qm/5tnispurZVN5dO9kH6cuOg2lWbn5D\n1UjKOIjXU0H36bsJHGhsxmu7LjOU9Kuy9LurSQliL1JkhDIaxOy6bi3kLIqM2gPtxXYjkNN59GEN\nMfthGzantJIeKap4ILhK2HnZOU7VnGwq7p/tk84wmyN3Xuah878HQ1QcReecuir+ue3b5BrTLg2m\nVuCAT6MUf2HpVNWpJ7PSC7qOVYYnnohk0dUkK2tOpPPCtXyuRgnPExo/dM0sFFEIYdP49qrsmTTD\nXxCB5VY4WslIFBA86D/eU/V5O/0OGqJSDis58g08oNmBk/S4XPLQuSSuMi1q66X6SI+qmAalGzpD\nSwg7b7dNCmIWKTJCGQVimpn/A9b0s2zgct3SKRfT8Dez4DqPF3ORbtOlw9WQYkX91d0hRA45xpXk\nLJr+kLpPFq0MMKkjXaF97arzIAWJzp2pPIDoKOs0ADx32ejejScxSyf3jknWnWqTe707Q8Aew9w8\n+FzoysdV6KHS51RuXeTUMn65wcVnBTQ4ZcYziVarGdPrpnSTzJlw3lQI7OuW91jI6OUpZtXWpYdn\nWA5N2bqjXi7bIW09OEW/l40CREJzdlSzv0WfvPYY9oKYRYqMUUaBmEDUbTwLR7rVjjSZdYsnkI7K\nlrlQcpqSDZ2Tt/CIKp3nSJFSQ7SODMnmITE7L+tQhyEbKSOhHkrWZUuk617ij/pa02WBFVlBIw+C\ngJqQ9gUAJzvWNYVwlXRJBVrsyQqZ6rn7+wogFzLG/Z1cFJrVeNvSFKvLixj8f0ruBHZSZ60nPrdE\nyJ6Pubc34z0VvkeXjdZznNlAzuT0LZImpEuSwzm76ZRqSKoZuZN6hSzW6afVLpZbrPO7pSBmkSIj\nlFEgZtd1ePzxx91f6cTHIn46FVNrasZ5af9E/r7VUJ7Pi/3ImpjpaRKNXgqMFtLJyiqNZa70KJIL\nK6ZM9BZ3vCimKGlsdt2Tbeq6Diumd8na6DOBJh1BZ3vSt6Kz/cxefO4l1/cYxib97vnPj6XwhoI+\nRJAlaRiZsqawu/XkZyWSd07cHNcnTL/a34/9Mjt1wOelVZqI8KUHHojb5bTv0hSrj3/8vrhKpNV+\n9fub3vCfx2eTtVvBD5N9R13p3BPqb5eZ9iUKEXf2V6kW7QECshBbeljoU/TOxZxSc1MUiK7gff9V\neXC/bpLeo5nUO2eA26QgZpEiI5RRIKYk9zV2mQ7pFBpepiANzgaG0bKxXOfbLko69jZU0klVriDV\nZ93i54m/UlIZFubWTel/hpr6hwcLeuRYWoDHLcNUqmaQxZhoxsgR+ScnvYK1ZbXlLdXELiTLoTwf\n0C3TYj/ydWKV6ohBTkSIpIyFd/jTOWCkD2hdXS5j5NCUgLFcpn7fCf2mK/Zvl/Uv0A/k0ApK9xmB\nLOSCQG88j+cqtovfYYfuKUmp3njNzKYgcYPtDkuwl7i3/IpXl4KYRYqMUMaBmBb9hbIy5r6vnHIE\nWXKzrQ1juyxfycC1JkMwTYrGHgSvoqdKalZisQKonYQqTWJWW48Wc08lk9V0SRQ6f+5s+ryicpTa\nx1yrfiUSKcbrapg+m1phh0B9+je39kQ8bm9G66usjJ5kHc+aMnJnIBXjNYnSiyskVz6IOqnoU3r6\nI4WobctYY84s9ukHVGmFThZnN2bb8C6krnnT0r51cbTa/sRZDeIhrGtDMt8sr1eFwQLsR8rSnf+g\nnPpyiy+++DGLFHl2yygQM4SAtm0H3VJWRCUMq3x4Rv0wxJ5ypAthiB7KXVo7ysHlI6EPq7XSt1RU\n1g+I1yOsKbNFfk9FssyYffHEpUPs7UVr6qRJSbNUJMjZSjxcSVSP1H+JNg1nCH6eCtaKVNjpLNlY\nRRBNstdcGZ48vIj1B+scTeK9b33Bbcm1+gwazhzExGChWMvY18VRXJ6hVTdwe8cCtksiLSr2hcfa\nSg83p+0IbFQnnyjv7WTUO+J08+T2jVmStdkWZbe70hq3XkUlHH436ezOE59OgI7bpCBmkSIjlFEg\nZtf1uHTpko9w8lOq9Lb0HZXU84KtKmegHMCwXlzh6hYw7Z3MpEtpC62xzBaoGJlSN7IUymIcR+3n\n3y5kidvls7x4OVJqfvSjH8XFK4fcl8aPfuWhR8AN8TlldeVo/LWveFmyvqd+oK4pqkgfvJ2ESgnG\nQpqUvjJUhnP0mYoyRGgxJbp/x3/xRvaPaDjS+Nz777+f14zrM/bT6VPx+HvueTnXow46naR2gktO\no6I2a3Y0Q6Ae27KUYitUFmHznIiZFQeqOcup6Q+vd0yGPHE6n1b5gfmGavexwraMLHqQAVGv3SZb\nELNIkVHKKBAzhIDVarWBmPLXeTm6Zvs4Yms+S8+4WEOHq99cuqcsgcoSkZ5H/W6aHidsnpMwWqRL\nyls8ffo0rwdMmcO4R7oN+U6/8nAsgqo8TDERuG402WMbqDOJhFoZLCvqa64fCtWHOF0AMGWjeF/0\neIw6ZtspjpaRT0Rjo9W2Zrk+7e94/P5pRiWR4WDJdzZntNEBKVemU1naI8otyQiB/bN8ZmX1iOJz\ngr7T34w/VSCzWCJaRV9pu4jB2H/6nWTGWo8PyqFrYz2NxY3r239Hg9U1z9PMb36CZEwUxCxSZJQy\nCsQ0i5kSlkXAeHGcvCBNn6LicJ319Wub0bdZ3qBzBSmgh0RQpsge6ZhZyfeNEnv0D87nc9eV5Aut\nGV2jHD6nacwcbkvP0JDOyOMWKpYrK3XKbOA5qOpHDfwOFYbpQURjRfh0bhmmTs18zaVn5XA/++XK\nEa3RzugQDxA3kFBd/l29qwn15JUKwbr/VD/FBoM+q/YrdlVl44nmHu/La+hV9Ol6TvljO9JLQoaK\nTl4W7AT6oZ6H1nzv892ou00KYhYpMkIZBWLm4rGxO5ZeZpzHT6jDhRPZvaKIT0ijrvIHHWw86sjN\nl/F/DcqKVtJeZ0YQxaJhQn1N1kbPJ5XeppG8TnVE8e/oWk2Gyu1S/kxZNGVt5MLk543r3ZoPt/MC\nsylPkMiU5SP00gnyESraqk4ZCKb6JXUpo4MYHqZ8FmX7uN4oBoBKfsxqjWGAfSjdEbJapwTYTsGJ\ndPvGz0E/GP/Vp/7L4bQBKa9X/NbXeY2CmEWKjFBGgZh9AK60neuIKy90E8edhRCFI1ur7HpPtKO+\nhKGctnx/KtleZaY4oc6l1aPxmq0KqdKnGJQ9QetiJX8nUa7VfaL1dW8i/YcxsmSZ+6+/+604PDxM\n9nkc6kXxxMZ7CZ2VP6nzVlkkVM3jz54/x/4hYTTRbUZf4oS5pTOWQxAP0aptcfftz4vXnFCXVGYP\no43u/8Kfs9+I8nxexbq++hu+Me5nnuWMCBpY2PWFt98Rr4uoi9YTRRjFtj44vwXr4qyCVuGVr/4G\n/xsYIn/E2Dc5q3eac/7QWo0dwkAqC/u7jkhlLaZ2F+7tYg/aNnk7CXYWxCxSZIQyCsQMCOj7foNl\nYJfk5fr6Ne5X99TJ2qr8SKkNefn0dih/nu63rcfnsbZDmfnUouxtMltj8UuPCRt67PYxNS/1Lo5b\nRf5In8vLsVeZH1jXn02nQ35hnnohhVf18aTXCrWckUApMGm2jeetDqkccd0zRbK2eg4lrcGofAZh\nGcvfwKO70UVfdVIQs0iREcooEBNhE4mS3TtQyzayCAZPlHTMWjqm+7QyxKu2I+GQoZDqf7lIXxQq\nbmSvhIA+KIuE96J5cGKyJm9/zl2FfLXfuX4mYl7XLIC6q9B7KY4cWYxrTFUPhjqj+2mJVtpvWYzs\nxAsYZbVh8hmJEFJt9uyeuC4mdi9oK6Stap8J9JU4b8H146AyRWnJRqTPswBxj0VMM/uXZvYVM/uj\ntW0XzOyDZvZZLm/hdjOz/8XM7jezPzSzb3o6G1+kyFerXAti/gKAnwPwr9e2vQvAh0IIP2Vm7+L6\njwH4LgCv4L/XA3g3l1cVM2NJ9AwBsxxK918650+UbTqmhyiKlTwLVdxVHDdHrVyHlMfSdazses5G\noLLujTn730b+qDsclfXOO2TH5WitKBpZa80LubLNXL/tttuSdd2vqiq0RzGm1Viib6V2TxgBRZQV\np5Hz9PZCY/kWqRv6jET6c4qQejOytDbM6nFLcxj6RLHE8kvL+m7VThvoVtlAymeRHIuYIYT/AOCx\nbPNbALyXf78XwFvXtv/rEOV3AZw3szueqsYWKfJckevVMW8LITzIv78M4Db+/SIAf7523APc9iAy\nMbN3AHgHAJyeTdE0zWC9DH4MgAGFhF5tp4iXeOCVI/oJQz/U1uRIrJFdWSLOgCZUmqbrIaSI6Jku\nmQ4p5vHLzLt0lM/S3vf29jAjV2s+I/jyxYfjeuaXlQ6qh1HbcwR9/LFHknt5/RT6FM8zA0Tr65k2\nd73wNnVUfE7FH8/EthDb7HUw6cec0HO3oI9V1tumFuuAyq1Ld5QoIyT27/NfcHvyLELzZd/h4AJ9\nnH0a4SV+ok1Rxo+/XZ2x4/jxyw1bZUP8pZ540hBCuDeE8NoQwmv3cuqLIkWe43K9X8RDZnZHCOFB\nTlW/wu1fAvDitePu5LariiHVMUOmU/UZA53rfUo28ayTDrlx1y2bvXSYKG5l3FFk0d16slbmtVBC\n6vd0PXdNjwOUNZNuk3RZHRRXTzOmPcXMaiahKl49uX/yamKyiJ4mG4HWPcmi79FTx5SlU0wG0hnF\neau6j4qZVfc6insOaZrX6bmT0jn5LEtef6o6JEJz9WPXDwqr/LPOw8Q42w3eprjctL6G5IBdIbRj\nlOtFzF8H8Db+/TYAH1jb/oO0zn4zgCfXprxFihS5RjkWMc3slwB8O4BbzewBAD8B4KcA/IqZvR3A\nFwF8Lw//TQBvBnA/gEMAf/NaGxJC2Bjxcv9dv2OsG6JIgkeQKI5SvK+qd7l57mY71u89LNP9EumP\n7qvc8GN20Fi9WqX1O5Q36Ry1OsfZ35Qtkl1T1spG0TKp/junH1CP7NWb16t9NWJ5F5zS2iqeJSLZ\njGitbBOPJlpmM4f8XQnVdXn3c8Y/joj2dV8nxy1XK9dbxYqgfW4/kL6/8Uq388ueJJtyLHLshxlC\n+P4du96w5dgA4G+dtBEhBISuH4rOrm3fJrkRRKXzKgSf5nT8VXoybfbB+QfYbv9grUrD2Ab2kvR4\nD37PPkx98E3TrLl/4jaf9mZsUf64KmngUzRNyXi+Eqn5AcodMxS4Td0MIqnW/ni8Mp9Fw6Ha9lry\nuRikrqAFc2JsblcpdxpmNHh2/kGK/lNpdcqX42CqNDIv/BsAJ9PSIBtPaRhg33pRoF1Ez3I/PXsD\n2569LS9S5KtYRmEOraoKBwcHO4PTVU5OFBtVNjU8JXLhbjUYdURANWX4GlI0kVGnpoHER36KjEVV\nnSKtRmNN4R57LLp4Na0UgjYkhDp37qyXKM9dL0smEYsqJHcXrUjfoYmEkox1vKahIuvSM83ovP/w\nhz8UW8yma/90OsVpEVYpTY1Ty4q0luduvRDvSTKu5TIlSPual78itmWVpnOdORtJtgRzp0/H9aVC\nH0n2dfvLI72ly9pERMRdyELw2p3l866OnPnWqxfhG4cUxCxSZIQyCsQEsDXtS0iRF4UVYubI2iMM\nxVwyChCJB1NvEHnV2TqRUki7YYtPDS5D9pTcKKkuCwyBAyG9hBc7VQkEx+ZWKB/XJ+4WopO/V7hg\nSJbuerDtLp4utOhEEenuEiL9hhErvbanYDnxFXjN1NjTOR2MAgf6pM257389lWsIgK829m2TwTQh\nl5XvufqJI5Znb8uLFPkqltEgJrAlsFxLD1Xb7spYT851Z3rm3shdLQOSamzKNY80kH5X/duBWlMI\nqXWGBDaN65+B3a1zpCOv2tSNkuvQHqKowPpORV9JZykCLYUqyvCZ6WQroXln6KTPZmF8zpUhXqtK\nVmbqs5y1zFmg1gMwtN9LSNAyLMsq08kmCvQw0YGksj7DyZHypIF2Xgph4wLjx6Pxt7BIkeegjAYx\nq6pydJLlLyDVmSRCilr0+h4IXW2MpgpXC1mCdE6JGTI9ZaAIIWLko3eWFuZEUJ4mxvt3S1jFYq30\n/ekeM5UhINqqiJJSq1ZLhRPKsx4X0kkrhZo1WZA7l81+ShBm7UDmpT5UmUGlZfn8gbpmS9hqPV4w\nSwrgswkxjQEJ6g8n0nJdlD2wA/Z6Oz5k7sQh6s+++IKCmEWKjFFGgZiVGaZ1sxGVkweO93mwNtdV\nwKaqtqBrhozDubxmk95j2O/JRmolV3V8XCrtS3qkULEhckymtfs03XdK/e75t70gbl/J98noGa57\n+UEGlIvWoyMqiyJT57mfVPSW9ClWk2z/pMEr7oy5BkK4ldK1uH723C1JW3Wu2rC/H1PKPCVPvld2\n04r9s2BKnvyYKvtw2w79cV12oerVCsryzHR14zrjx6Pxt7BIkeegjAIxgVTH3EUVeRxZlVm1gbZ5\nsaAN+koCY8hGWblUFXSd+/VyHdOzpVTGztfbofxARkdycJr6WTOkiAFA53G2igVmxFOtFsjSKYsq\n26ztJFeWjqnSgFU7WIr9HlkMq7cbigFWbGxaHGjQMVXGgDOGrNycZiyt2w30DNsxIaLktZWsG34d\nni+X79h+wjUrpzdPCmIWKTJCGQ1iAsdnk+yic+zXxuF8MHSExHa0HQ5MdcidfszhDwADylVOA0Kr\npaJ5msb1TYnQRn7KPiOblg7pfk7ROWZl+2QpVRST/JmTPkXawHXt77q1pGlZU1VmQP7MtWLA8UHY\nK3y++ZJkXjQVD37QlCpEswWhv2Xpd9v0yAFNU+T0iCj+cbyu+eyVgphFioxQRoOYfd/vLBEgyfdv\nlEiw4wvxHYe+2LF/F2IepweHENaOEQJkJd21VbGwpPPwEn+0qk6Y3OyFbhUZlBNCZ9FPOQFZG3pH\nU2Okkvy98o0qckfnej94JBB9yETEPkdCt9ayrUqwzmJqc/kqBsETSUHMIkVGKHa10gTPWCPMHgZw\nBcAjxx17k+RWlLZdj4y1bTerXS8NITz/Wg4cxYcJAGZ2XwjhtTe7HduktO36ZKxtG2u71qVMZYsU\nGaGUD7NIkRHKmD7Me292A64ipW3XJ2Nt21jb5TIaHbNIkSKDjAkxixQpQhnFh2lmbzKzP2bB23fd\nxHa82Mw+YmafMrNPmtk7uX1rod6b1MbazD5hZr/B9bvN7KPsu182U/2yZ7xd583s/Wb2GTP7tJl9\ny1j6zcx+hO/zj8zsl8xsbyz9tktu+odpMZjynyIWvX0lgO83s1fepOa0AP5OCOGVAL4ZwN9iW1So\n9xUAPsT1myXvBPDptfWfBvAzIYSXA3gcwNtvSquAnwXwWyGErwPwasQ23vR+M7MXAfjbAF4bQvh6\nxLCr78N4+m27KGTsZv0D8C0Afntt/ccB/PjNbhfb8gEAbwTwxwDu4LY7APzxTWrPnYg/8O8A8BuI\n0XyPAGi29eUz2K5zAD4P2izWtt/0fsNQs/UCYgjqbwD4r8bQb1f7d9MRE7uL3d5UMbO7ALwGwEex\nu1DvMy3/BMDfxRB0+zwAT4QQRCN/s/rubgAPA/hXnGb/CzM7hRH0WwjhSwD+EYA/Qyyg/CSAj2Ec\n/bZTxvBhjk7M7DSAXwXwwyGEi+v7Qhxin3FTtpn9NQBfCSF87Jm+9zVIA+CbALw7hPAaxPDKZNp6\nE/vtFgBvQRw8XgjgFIA3PdPtOKmM4cO8rmK3T5eY2QTxo/zFEMKvcfNDLNCLrFDvMynfCuC7zewL\nAN6HOJ39WQDnTcVRbl7fPQDggRDCR7n+fsQPdQz99p0APh9CeDiEsALwa4h9OYZ+2ylj+DB/D8Ar\naCWbIirmv34zGmIxt+k9AD4dQvjHa7t2Fep9xiSE8OMhhDtDCHch9tGHQwh/A8BHAHzPTW7blwH8\nuZl9LTe9AcCnMIJ+Q5zCfrOZHfD9qm03vd+uKjdbyaXy/WYAfwLgTwH8zzexHd+GON36QwC/m+t/\n5AAAAIdJREFUz39vRtTlPgTgswD+bwAXbnJ/fTuA3+Df9wD4/xCLBf8fAGY3qU3fCOA+9t2/BXDL\nWPoNwD8A8BkAfwTgfwcwG0u/7fpXIn+KFBmhjGEqW6RIkUzKh1mkyAilfJhFioxQyodZpMgIpXyY\nRYqMUMqHWaTICKV8mEWKjFDKh1mkyAjl/weE7AvcqwxGfwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc82ffd31d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(X_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 96, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#     X_train = load_data('lr_training.txt')\n",
    "#     y_train = load_data2('hr_training.txt')\n",
    "#     X_test = load_data('lr_val.txt')\n",
    "#     y_test = load_data2('hr_val.txt')\n",
    "    # Create the HDF5 file\n",
    "    f = h5py.File('data.h5', 'w')\n",
    "\n",
    "    # Create the image and palette dataspaces\n",
    "    dset = f.create_dataset('lr_train', data=X_train)\n",
    "    pset = f.create_dataset('hr_train', data=y_train)\n",
    "    lset = f.create_dataset('lr_test', data = X_test)\n",
    "    sset = f.create_dataset('hr_test', data = y_test)\n",
    "\n",
    "    # Close the file\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain = []\n",
    "ytrain = []\n",
    "xval = []\n",
    "yval = []\n",
    "for i in range(X_train.shape[0]):\n",
    "    xtrain.append(downsample(y_train[i],4))\n",
    "    ytrain.append(y_train[i])\n",
    "for i in range(X_test.shape[0]):\n",
    "    xval.append(downsample(y_test[i],4))\n",
    "    yval.append(y_test[i])   \n",
    "                \n",
    "xtrain = np.asarray(xtrain)\n",
    "ytrain = np.asarray(ytrain)\n",
    "xval = np.asarray(xval)\n",
    "yval = np.asarray(yval)\n",
    "import h5py\n",
    "f = h5py.File('data_small.h5', 'w')\n",
    "\n",
    "# Create the image and palette dataspaces\n",
    "dset = f.create_dataset('lr_train', data=xtrain)\n",
    "pset = f.create_dataset('hr_train', data=ytrain)\n",
    "lset = f.create_dataset('lr_test', data = xval)\n",
    "sset = f.create_dataset('hr_test', data = yval)\n",
    "\n",
    "# Close the file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.engine import  Model\n",
    "from keras.layers import Input\n",
    "from keras_vggface import VGGFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_conv_feature(img_list):\n",
    "    features = []\n",
    "    image_input = Input(shape=(112, 96, 3))\n",
    "    vgg_model = VGGFace(input_tensor=image_input, include_top=False) # pooling: None, avg or max\n",
    "    out = vgg_model.get_layer('pool5').output\n",
    "    vgg_conv = Model(image_input, out)\n",
    "    for i in range(len(img_list)):\n",
    "        x = img_preprocess(img_list[i])\n",
    "        preds = vgg_conv.predict(x)\n",
    "        features.append(preds)\n",
    "    return np.asarray(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_preprocess(img):\n",
    "        img = img.astype(np.float64)\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        # TF order aka 'channel-last'\n",
    "        x = x[:, :, :, ::-1]\n",
    "        # TH order aka 'channel-first'\n",
    "        # x = x[:, ::-1, :, :]\n",
    "        # Zero-center by mean pixel\n",
    "        x[:, 0, :, :] -= 93.5940\n",
    "        x[:, 1, :, :] -= 104.7624\n",
    "        x[:, 2, :, :] -= 129.1863\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = retrieve_conv_feature(y_test[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def gram_matrix(x):\n",
    "    features = K.batch_flatten(x)\n",
    "    gram = K.dot(features - 1, K.transpose(features - 1))\n",
    "    return gram\n",
    "\n",
    "# vgg conv_loss\n",
    "def conv_loss(style, combination):\n",
    "\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = 112 * 96\n",
    "    return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = vgg_model.predict(y_test[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test[0:20].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrieve feature maps from VGG \n",
    "def retrieve_conv_feature(img_list):\n",
    "    image_input = Input(shape=(112, 96, 3))\n",
    "    vgg_model = VGGFace(input_tensor=image_input, include_top=False) # pooling: None, avg or max\n",
    "    out = vgg_model.get_layer('pool5').output\n",
    "    vgg_conv = Model(image_input, out)\n",
    "    preds = vgg_conv.predict(img_list)\n",
    "    return preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = retrieve_conv_feature(y_test[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "    y_train = (y_train.astype(np.float32) - 127.5)/127.5\n",
    "    print('Data Normalized.')\n",
    "\n",
    "    #   Reshape the img in the format of (number of rows, channels, height, weight)\n",
    "    y_train = y_train.reshape((y_train.shape[0], 3) + y_train.shape[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.preprocessing import image\n",
    "from keras.layers.core import Dropout\n",
    "from keras.engine import  Model\n",
    "from keras.layers import Input\n",
    "from keras_vggface import VGGFace\n",
    "from scipy.misc import imsave\n",
    "from Utils import conv_loss, gram_matrix\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import math\n",
    "import Data as Data\n",
    "\n",
    "\n",
    "\n",
    "def cnn_model():\n",
    " \n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(3, 28, 24)))\n",
    "    model.add(Dense(16*28*24, init='uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Reshape((16, 28, 24), input_shape=(16*28*24,)))\n",
    "    model.add(Convolution2D(64, 5, 5, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(32, 5, 5, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(16, 5, 5, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(3, 5, 5, border_mode='same'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(64, 5, 5, border_mode='same', input_shape=(3, 28, 24)))\n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Convolution2D(32, 5, 5, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(32, 5, 5, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(16, 5, 5, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(3, 5, 5, border_mode='same'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(\n",
    "                        16, 5, 5,\n",
    "                        border_mode='same',\n",
    "                        input_shape=(3, 112, 96)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Convolution2D(32, 5, 5))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Convolution2D(64, 5, 5))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Convolution2D(96, 5, 5))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def generator_containing_discriminator(generator, discriminator):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    discriminator.trainable = False\n",
    "    model.add(discriminator)\n",
    "    return model\n",
    "\n",
    "#retrive the first image in predicting set\n",
    "def combine_images(generated_images):\n",
    "    generated_images = generated_images.reshape(128,112,96,3)\n",
    "    image = generated_images[0,:,:,:]\n",
    "    return image\n",
    "\n",
    "# Zero-center by mean pixel\n",
    "def img_preprocess(img):\n",
    "        img = img.astype(np.float64)\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        # TF order aka 'channel-last'\n",
    "        x = x[:, :, :, ::-1]\n",
    "        # TH order aka 'channel-first'\n",
    "        # x = x[:, ::-1, :, :]\n",
    "        # Zero-center by mean pixel\n",
    "        x[:, 0, :, :] -= 93.5940\n",
    "        x[:, 1, :, :] -= 104.7624\n",
    "        x[:, 2, :, :] -= 129.1863\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    " # Training supervised by feature layer wise (perceptual similarity)\n",
    "def train(BATCH_SIZE):\n",
    "    # load the training data\n",
    "    print('Data loading..')\n",
    "    X_train, y_train, X_test, y_test = Data.loadData('data_small.h5')\n",
    "    print('Data Loaded. Now normalizing..')\n",
    "    \n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    y_train = (y_train.astype(np.float32) - 127.5)/127.5\n",
    "    print('Data Normalized.')\n",
    "\n",
    "    #   Reshape the img in the format of (number of rows, channels, height, weight)\n",
    "    X_train = X_train.reshape((X_train.shape[0], 3) + X_train.shape[1:3])\n",
    "    y_train = y_train.reshape((y_train.shape[0], 3) + y_train.shape[1:3])\n",
    "\n",
    "    discriminator = discriminator_model()\n",
    "    generator = generator_model()\n",
    "    discriminator_on_generator = \\\n",
    "        generator_containing_discriminator(generator, discriminator)\n",
    "\n",
    "        \n",
    "    d_optim = RMSprop(lr=0.00001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    g_optim = RMSprop(lr=0.0001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    generator.compile(loss= conv_loss, optimizer=g_optim)\n",
    "#    discriminator_on_generator.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "#    discriminator.trainable = True\n",
    "#    discriminator.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
    "    noise = np.zeros((BATCH_SIZE, 100))\n",
    "    shape = []\n",
    "    for epoch in range(100):\n",
    "        print(\"Epoch is\", epoch)\n",
    "        print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
    "        for index in range(int(X_train.shape[0]/BATCH_SIZE)):\n",
    "            # Random Signal Goes here (if needed)\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "\n",
    "            lr_image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            hr_image_batch = y_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            generated_images = generator.predict(lr_image_batch, verbose=0)\n",
    "            shape = generated_images.shape\n",
    "\n",
    "            if index % 10 == 0:\n",
    "                image = combine_images(generated_images)\n",
    "                image = image* 127.5+ 127.5\n",
    "                imsave(\"./image_result/\"+str(epoch)+\"_\"+str(index)+\".png\", image.astype(np.uint8))\n",
    "            X = np.concatenate((hr_image_batch, generated_images))\n",
    "            y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "#            d_loss = discriminator.train_on_batch(X, y)\n",
    "#            print(\"batch %d d_loss : %f\" % (index, d_loss))\n",
    "\n",
    "#            for i in range(BATCH_SIZE):\n",
    "#                noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "#            discriminator.trainable = False\n",
    "            \n",
    "            #retrieve conv_loss of images\n",
    "            conv_lr_image_batch = retrieve_conv_feature(generated_images.reshape(generated_images.shape[0], generated_images.shape[2],generated_images.shape[3] ,3))\n",
    "            conv_hr_image_batch = retrieve_conv_feature(hr_image_batch.reshape(hr_image_batch.shape[0], hr_image_batch.shape[2],hr_image_batch.shape[3] ,3))\n",
    "            \n",
    "            #g_loss = 0.1* discriminator_on_generator.train_on_batch( lr_image_batch, [1] * BATCH_SIZE) \n",
    "            g_loss = generator.train_on_batch(conv_lr_image_batch, conv_hr_image_batch)\n",
    "#            discriminator.trainable = True\n",
    "            print(\"batch %d g_loss : %f\" % (index, g_loss))\n",
    "#            print(shape)\n",
    "            if index % 10 == 9:\n",
    "                generator.save_weights('generator', True)\n",
    "#                discriminator.save_weights('discriminator', True)\n",
    "   \n",
    "\n",
    " # Training in MSE loss function (pixel wise training)\n",
    "def MSE(BATCH_SIZE):\n",
    "    # load the training data\n",
    "    print('Data loading..')\n",
    "    X_train, y_train, X_test, y_test = Data.loadData('data_small.h5')\n",
    "    print('Data Loaded. Now normalizing..')\n",
    "    \n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    y_train = (y_train.astype(np.float32) - 127.5)/127.5\n",
    "    print('Data Normalized.')\n",
    "\n",
    "    #   Reshape the img in the format of (number of rows, channels, height, weight)\n",
    "    X_train = X_train.reshape((X_train.shape[0], 3) + X_train.shape[1:3])\n",
    "    y_train = y_train.reshape((y_train.shape[0], 3) + y_train.shape[1:3])\n",
    "\n",
    "    discriminator = discriminator_model()\n",
    "    generator = generator_model()\n",
    "    discriminator_on_generator = \\\n",
    "        generator_containing_discriminator(generator, discriminator)\n",
    "\n",
    "        \n",
    "    d_optim = RMSprop(lr=0.00001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    g_optim = RMSprop(lr=0.0001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    generator.compile(loss='mean_squared_error', optimizer=g_optim)\n",
    "    discriminator_on_generator.compile(\n",
    "        loss='binary_crossentropy', optimizer=g_optim)\n",
    "    discriminator.trainable = True\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
    "    noise = np.zeros((BATCH_SIZE, 100))\n",
    "    shape = []\n",
    "    for epoch in range(100):\n",
    "        print(\"Epoch is\", epoch)\n",
    "        print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
    "        for index in range(int(X_train.shape[0]/BATCH_SIZE)):\n",
    "            # Random Signal Goes here (if needed)\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "\n",
    "            lr_image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            hr_image_batch = y_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            generated_images = generator.predict(lr_image_batch, verbose=0)\n",
    "            shape = generated_images.shape\n",
    "\n",
    "            if index % 10 == 0:\n",
    "                image = combine_images(generated_images)\n",
    "                image = image* 127.5+ 127.5\n",
    "                imsave(\"./image_result/\"+str(epoch)+\"_\"+str(index)+\".png\", image.astype(np.uint8))\n",
    "            X = np.concatenate((hr_image_batch, generated_images))\n",
    "            y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "            d_loss = discriminator.train_on_batch(X, y)\n",
    "            print(\"batch %d d_loss : %f\" % (index, d_loss))\n",
    "\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "            discriminator.trainable = False\n",
    "            \n",
    "\n",
    "            g_loss = discriminator_on_generator.train_on_batch(\n",
    "               lr_image_batch, [1] * BATCH_SIZE)\n",
    "            # generator.train_on_batch(lr_image_batch, hr_image_batch)\n",
    "            discriminator.trainable = True\n",
    "            print(\"batch %d g_loss : %f\" % (index, g_loss))\n",
    "#            print(shape)\n",
    "            if index % 10 == 9:\n",
    "                generator.save_weights('generator', True)\n",
    "                discriminator.save_weights('discriminator', True)\n",
    "                \n",
    "                \n",
    "# def generate(BATCH_SIZE, nice=False):\n",
    "#     generator = generator_model()\n",
    "#     generator.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "#     generator.load_weights('generator')\n",
    "#     if nice:\n",
    "#         discriminator = discriminator_model()\n",
    "#         discriminator.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "#         discriminator.load_weights('discriminator')\n",
    "#         noise = np.zeros((BATCH_SIZE*20, 100))\n",
    "#         for i in range(BATCH_SIZE*20):\n",
    "#             noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "#         generated_images = generator.predict(noise, verbose=1)\n",
    "#         d_pret = discriminator.predict(generated_images, verbose=1)\n",
    "#         index = np.arange(0, BATCH_SIZE*20)\n",
    "#         index.resize((BATCH_SIZE*20, 1))\n",
    "#         pre_with_index = list(np.append(d_pret, index, axis=1))\n",
    "#         pre_with_index.sort(key=lambda x: x[0], reverse=True)\n",
    "#         nice_images = np.zeros((BATCH_SIZE, 1) +\n",
    "#                                (generated_images.shape[2:]), dtype=np.float32)\n",
    "#         for i in range(int(BATCH_SIZE)):\n",
    "#             idx = int(pre_with_index[i][1])\n",
    "#             nice_images[i, 0, :, :] = generated_images[idx, 0, :, :]\n",
    "#         image = combine_images(nice_images)\n",
    "#     else:\n",
    "#         noise = np.zeros((BATCH_SIZE, 100))\n",
    "#         for i in range(BATCH_SIZE):\n",
    "#             noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "#         generated_images = generator.predict(noise, verbose=1)\n",
    "#         image = combine_images(generated_images)\n",
    "#     image = image*127.5+127.5\n",
    "#     Image.fromarray(image.astype(np.uint8)).save(\n",
    "# #         \"./image_result/generated_image.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "    # load the training data\n",
    "    print('Data loading..')\n",
    "    X_train, y_train, X_test, y_test = Data.loadData('data_small.h5')\n",
    "    print('Data Loaded. Now normalizing..')\n",
    "    \n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    y_train = (y_train.astype(np.float32) - 127.5)/127.5\n",
    "    print('Data Normalized.')\n",
    "\n",
    "    #   Reshape the img in the format of (number of rows, channels, height, weight)\n",
    "    X_train = X_train.reshape((X_train.shape[0], 3) + X_train.shape[1:3])\n",
    "    y_train = y_train.reshape((y_train.shape[0], 3) + y_train.shape[1:3])\n",
    "\n",
    "    discriminator = discriminator_model()\n",
    "    generator = generator_model()\n",
    "    discriminator_on_generator = \\\n",
    "        generator_containing_discriminator(generator, discriminator)\n",
    "\n",
    "        \n",
    "    d_optim = RMSprop(lr=0.00001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    g_optim = RMSprop(lr=0.0001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    generator.compile(loss= conv_loss, optimizer=g_optim)\n",
    "#    discriminator_on_generator.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "#    discriminator.trainable = True\n",
    "#    discriminator.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
    "    shape = []\n",
    "\n",
    "    index =1\n",
    "    BATCH_SIZE = 128\n",
    "    lr_image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "    hr_image_batch = y_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "    generated_images = generator.predict(lr_image_batch, verbose=0)\n",
    "    shape = generated_images.shape\n",
    "\n",
    "    if index % 10 == 0:\n",
    "        image = combine_images(generated_images)\n",
    "        image = image* 127.5+ 127.5\n",
    "        imsave(\"./image_result/\"+str(epoch)+\"_\"+str(index)+\".png\", image.astype(np.uint8))\n",
    "    X = np.concatenate((hr_image_batch, generated_images))\n",
    "    y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "#            d_loss = discriminator.train_on_batch(X, y)\n",
    "#            print(\"batch %d d_loss : %f\" % (index, d_loss))\n",
    "\n",
    "#            for i in range(BATCH_SIZE):\n",
    "#                noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "#            discriminator.trainable = False\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = generated_images.reshape(generated_images.shape[0], generated_images.shape[2],generated_images.shape[3] ,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrieve feature maps from VGG \n",
    "def retrieve_conv_feature(img_list):\n",
    "    image_input = Input(shape=(112, 96, 3))\n",
    "    vgg_model = VGGFace(input_tensor=image_input, include_top=False) # pooling: None, avg or max\n",
    "    out = vgg_model.get_layer('pool5').output\n",
    "    vgg_conv = Model(image_input, out)\n",
    "    preds = vgg_conv.predict(img_list)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = retrieve_conv_feature(y_test[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    image_input = Input(shape=(112, 96, 3))\n",
    "    vgg_model = VGGFace(input_tensor=image_input, include_top=False) # pooling: None, avg or max\n",
    "    out = vgg_model.get_layer('pool5').output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    features = []\n",
    "    img_list = y_test[0:20]\n",
    "    image_input = Input(shape=(112, 96, 3))\n",
    "    vgg_model = VGGFace(input_tensor=image_input, include_top=False) # pooling: None, avg or max\n",
    "    out = vgg_model.get_layer('pool5').output\n",
    "    vgg_conv = Model(image_input, out)\n",
    "    for i in range(len(img_list)):\n",
    "        x = img_preprocess(img_list[i])\n",
    "        preds = vgg_conv.predict(x)\n",
    "        features.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        image_input = Input(shape=(112, 96, 3))\n",
    "        vgg_model = VGGFace(input_tensor=image_input, include_top=False) # pooling: None, avg or max\n",
    "        out = vgg_model.get_layer('pool5').output\n",
    "        vgg_conv = Model(image_input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading..\n",
      "Data Loaded. Now normalizing..\n",
      "Data Normalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:32: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10752, kernel_initializer=\"uniform\")`\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), padding=\"same\")`\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (5, 5), padding=\"same\")`\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:42: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (5, 5), padding=\"same\")`\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(3, (5, 5), padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch is', 0)\n",
      "('Number of batches', 659)\n",
      "batch 0 g_loss : 0.008772\n",
      "batch 1 g_loss : 0.018026\n",
      "batch 2 g_loss : 0.005628\n",
      "batch 3 g_loss : 0.001622\n",
      "batch 4 g_loss : 0.001526\n",
      "batch 5 g_loss : 0.002980\n",
      "batch 6 g_loss : 0.003342\n",
      "batch 7 g_loss : 0.002066\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8c6bec645aea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg_conv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhr_image_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_vgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_image_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch %d g_loss : %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m    939\u001b[0m         return self.model.train_on_batch(x, y,\n\u001b[1;32m    940\u001b[0m                                          \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m                                          class_weight=class_weight)\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     def test_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1619\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2103\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.preprocessing import image\n",
    "from keras.layers.core import Dropout\n",
    "from keras.engine import  Model\n",
    "from keras.layers import Input\n",
    "from keras_vggface import VGGFace\n",
    "from scipy.misc import imsave\n",
    "from Utils import conv_loss, gram_matrix\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import math\n",
    "import Data as Data\n",
    "\n",
    "\n",
    "#srcnn_vgg combine\n",
    "def cnn_model():\n",
    " \n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(3, 28, 24)))\n",
    "    model.add(Dense(16*28*24, init='uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Reshape((16, 28, 24), input_shape=(16*28*24,)))\n",
    "    model.add(Convolution2D(64, 5, 5, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(32, 5, 5, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(16, 5, 5, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(3, 5, 5, border_mode='same'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def generator_containing_discriminator(generator, discriminator):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    discriminator.trainable = False\n",
    "    model.add(discriminator)\n",
    "    return model\n",
    "\n",
    "#retrive the first image in predicting set\n",
    "def combine_images(generated_images):\n",
    "    generated_images = generated_images.reshape(128,112,96,3)\n",
    "    image = generated_images[0,:,:,:]\n",
    "    return image\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "# load the training data\n",
    "print('Data loading..')\n",
    "X_train, y_train, X_test, y_test = Data.loadData('data_small.h5')\n",
    "print('Data Loaded. Now normalizing..')\n",
    "\n",
    "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "y_train = (y_train.astype(np.float32) - 127.5)/127.5\n",
    "print('Data Normalized.')\n",
    "\n",
    "#   Reshape the img in the format of (number of rows, channels, height, weight)\n",
    "X_train = X_train.reshape((X_train.shape[0], 3) + X_train.shape[1:3])\n",
    "y_train = y_train.reshape((y_train.shape[0], 3) + y_train.shape[1:3])\n",
    "\n",
    "#vgg model goes here\n",
    "image_input = Input(shape=(3, 112, 96))\n",
    "vgg_model = VGGFace(input_tensor=image_input, include_top=False, pooling='avg') # pooling: None, avg or max\n",
    "out = vgg_model.get_layer('pool5').output\n",
    "vgg_conv = Model(image_input, out)\n",
    "\n",
    "#generator model goes here\n",
    "generator = cnn_model()\n",
    "generator_vgg = \\\n",
    "        generator_containing_discriminator(generator, vgg_conv)\n",
    "    \n",
    "d_optim = RMSprop(lr=0.00001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "g_optim = RMSprop(lr=0.0001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "generator.compile(loss='mean_squared_error', optimizer=g_optim)\n",
    "generator_vgg.compile(\n",
    "    loss=conv_loss, optimizer=g_optim)\n",
    "\n",
    "for epoch in range(100):\n",
    "    print(\"Epoch is\", epoch)\n",
    "    print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
    "    for index in range(int(X_train.shape[0]/BATCH_SIZE)):\n",
    "        lr_image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "        hr_image_batch = y_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "        generated_images = generator.predict(lr_image_batch, verbose=0)\n",
    "        shape = generated_images.shape\n",
    "\n",
    "        if index % 10 == 0:\n",
    "            image = combine_images(generated_images)\n",
    "            image = image* 127.5+ 127.5\n",
    "            imsave(\"./image_result/\"+str(epoch)+\"_\"+str(index)+\".png\", image.astype(np.uint8))\n",
    "        X = np.concatenate((hr_image_batch, generated_images))\n",
    "        y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "        \n",
    "        #generate feature labels for the hr_images\n",
    "        labels = vgg_conv.predict(hr_image_batch)\n",
    "        \n",
    "        g_loss = generator_vgg.train_on_batch(lr_image_batch, labels)\n",
    "\n",
    "        print(\"batch %d g_loss : %f\" % (index, g_loss))\n",
    "        if index % 10 == 9:\n",
    "            generator.save_weights('generator', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
